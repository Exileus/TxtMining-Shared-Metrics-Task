{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ideal-peninsula",
   "metadata": {},
   "source": [
    "### Implementation of LASER to the corpus\n",
    "### CS-EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "otherwise-sullivan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-metabolism",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lyric-olympus",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "split-terminology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11585 entries, 0 to 11584\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   source       11585 non-null  object \n",
      " 1   reference    11585 non-null  object \n",
      " 2   translation  11585 non-null  object \n",
      " 3   z-score      11585 non-null  float64\n",
      " 4   avg-score    11585 non-null  float64\n",
      " 5   annotators   11585 non-null  int64  \n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 543.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "political-spyware",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uchopíte pak zbraň mezi své předloktí a rameno...</td>\n",
       "      <td>You will then grab the weapon between your for...</td>\n",
       "      <td>You then grasp the gun between your forearm an...</td>\n",
       "      <td>-0.675383</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ale je-li New York změna, pak je to také znovu...</td>\n",
       "      <td>But if New York is changed, then it's also a r...</td>\n",
       "      <td>But if New York is change, it is also reinvent...</td>\n",
       "      <td>-0.829403</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dlouho a intenzivně jsem během léta přemýšlel,...</td>\n",
       "      <td>I have been thinking over and over again over ...</td>\n",
       "      <td>I have thought long and hard over the course o...</td>\n",
       "      <td>0.803185</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Najdou si jiný způsob, jak někde podvádět.</td>\n",
       "      <td>They find another way to cheat somewhere.</td>\n",
       "      <td>They will find another way how to defraud others.</td>\n",
       "      <td>0.563149</td>\n",
       "      <td>90.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zpráva o výměně v čele prezidentovy administra...</td>\n",
       "      <td>The report on the replacement of the president...</td>\n",
       "      <td>The news of the replacement at the top of the ...</td>\n",
       "      <td>0.021549</td>\n",
       "      <td>74.666667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Uchopíte pak zbraň mezi své předloktí a rameno...   \n",
       "1  Ale je-li New York změna, pak je to také znovu...   \n",
       "2  Dlouho a intenzivně jsem během léta přemýšlel,...   \n",
       "3         Najdou si jiný způsob, jak někde podvádět.   \n",
       "4  Zpráva o výměně v čele prezidentovy administra...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  You will then grab the weapon between your for...   \n",
       "1  But if New York is changed, then it's also a r...   \n",
       "2  I have been thinking over and over again over ...   \n",
       "3          They find another way to cheat somewhere.   \n",
       "4  The report on the replacement of the president...   \n",
       "\n",
       "                                         translation   z-score  avg-score  \\\n",
       "0  You then grasp the gun between your forearm an... -0.675383  60.000000   \n",
       "1  But if New York is change, it is also reinvent... -0.829403  44.000000   \n",
       "2  I have thought long and hard over the course o...  0.803185  96.500000   \n",
       "3  They will find another way how to defraud others.  0.563149  90.500000   \n",
       "4  The news of the replacement at the top of the ...  0.021549  74.666667   \n",
       "\n",
       "   annotators  \n",
       "0           3  \n",
       "1           2  \n",
       "2           2  \n",
       "3           2  \n",
       "4           3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-forum",
   "metadata": {},
   "source": [
    "Comparison of LASER embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stylish-eight",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_arr = np.load(\"laser.source_embeds.npy\")\n",
    "refer_arr = np.load(\"laser.reference_embeds.npy\")\n",
    "trans_arr = np.load(\"laser.translation_embeds.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-titanium",
   "metadata": {},
   "source": [
    "Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "special-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_similarity_ref_hyp = []\n",
    "cos_similarity_src_ref = []\n",
    "cos_similarity_src_hyp = []\n",
    "\n",
    "# for each of the cos similarity, put them into lists.\n",
    "for i in range(refer_arr.shape[0]):\n",
    "    cos_similarity_ref_hyp.append((spatial.distance.cosine(refer_arr[i],trans_arr[i])*-1)+1)\n",
    "    cos_similarity_src_ref.append((spatial.distance.cosine(source_arr[i],refer_arr[i])*-1)+1)\n",
    "    cos_similarity_src_hyp.append((spatial.distance.cosine(source_arr[i],trans_arr[i])*-1)+1)\n",
    "\n",
    "\n",
    "# Standardize and transform into series.\n",
    "scaler = StandardScaler()\n",
    "cs_rh = pd.Series(scaler.fit_transform(np.array(cos_similarity_ref_hyp).reshape(-1,1)).flatten(),name=\"cos_sim_ref_hyp\")\n",
    "cs_sr = pd.Series(scaler.fit_transform(np.array(cos_similarity_src_ref).reshape(-1,1)).flatten(),name=\"cos_sim_src_ref\")\n",
    "cs_sh = pd.Series(scaler.fit_transform(np.array(cos_similarity_src_hyp).reshape(-1,1)).flatten(),name=\"cos_sim_src_hyp\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "suspected-october",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cos_sim_ref_hyp</th>\n",
       "      <th>cos_sim_src_ref</th>\n",
       "      <th>cos_sim_src_hyp</th>\n",
       "      <th>z-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.944591</td>\n",
       "      <td>-0.059577</td>\n",
       "      <td>0.313330</td>\n",
       "      <td>-0.675383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.310273</td>\n",
       "      <td>-0.699820</td>\n",
       "      <td>0.766601</td>\n",
       "      <td>-0.829403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.610518</td>\n",
       "      <td>0.229530</td>\n",
       "      <td>0.876500</td>\n",
       "      <td>0.803185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.546027</td>\n",
       "      <td>0.187428</td>\n",
       "      <td>0.142012</td>\n",
       "      <td>0.563149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.589712</td>\n",
       "      <td>0.537170</td>\n",
       "      <td>-0.510440</td>\n",
       "      <td>0.021549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cos_sim_ref_hyp  cos_sim_src_ref  cos_sim_src_hyp   z-score\n",
       "0         0.944591        -0.059577         0.313330 -0.675383\n",
       "1        -0.310273        -0.699820         0.766601 -0.829403\n",
       "2         0.610518         0.229530         0.876500  0.803185\n",
       "3        -0.546027         0.187428         0.142012  0.563149\n",
       "4        -0.589712         0.537170        -0.510440  0.021549"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_df = pd.concat([cs_rh,cs_sr,cs_sh,df1.loc[:,\"z-score\"]],axis=1)\n",
    "cos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "extended-beijing",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise Pearson\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cos_sim_ref_hyp</th>\n",
       "      <th>cos_sim_src_ref</th>\n",
       "      <th>cos_sim_src_hyp</th>\n",
       "      <th>z-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cos_sim_ref_hyp</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.604009</td>\n",
       "      <td>0.797262</td>\n",
       "      <td>0.430993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_sim_src_ref</th>\n",
       "      <td>0.604009</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.682677</td>\n",
       "      <td>0.193411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_sim_src_hyp</th>\n",
       "      <td>0.797262</td>\n",
       "      <td>0.682677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.279916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z-score</th>\n",
       "      <td>0.430993</td>\n",
       "      <td>0.193411</td>\n",
       "      <td>0.279916</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 cos_sim_ref_hyp  cos_sim_src_ref  cos_sim_src_hyp   z-score\n",
       "cos_sim_ref_hyp         1.000000         0.604009         0.797262  0.430993\n",
       "cos_sim_src_ref         0.604009         1.000000         0.682677  0.193411\n",
       "cos_sim_src_hyp         0.797262         0.682677         1.000000  0.279916\n",
       "z-score                 0.430993         0.193411         0.279916  1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pearson\n",
    "print(\"Pairwise Pearson\")\n",
    "cos_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "developmental-strengthening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise Kendall\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cos_sim_ref_hyp</th>\n",
       "      <th>cos_sim_src_ref</th>\n",
       "      <th>cos_sim_src_hyp</th>\n",
       "      <th>z-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cos_sim_ref_hyp</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.412618</td>\n",
       "      <td>0.617482</td>\n",
       "      <td>0.293171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_sim_src_ref</th>\n",
       "      <td>0.412618</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.519509</td>\n",
       "      <td>0.134352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_sim_src_hyp</th>\n",
       "      <td>0.617482</td>\n",
       "      <td>0.519509</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.178779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z-score</th>\n",
       "      <td>0.293171</td>\n",
       "      <td>0.134352</td>\n",
       "      <td>0.178779</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 cos_sim_ref_hyp  cos_sim_src_ref  cos_sim_src_hyp   z-score\n",
       "cos_sim_ref_hyp         1.000000         0.412618         0.617482  0.293171\n",
       "cos_sim_src_ref         0.412618         1.000000         0.519509  0.134352\n",
       "cos_sim_src_hyp         0.617482         0.519509         1.000000  0.178779\n",
       "z-score                 0.293171         0.134352         0.178779  1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kendall\n",
    "print(\"Pairwise Kendall\")\n",
    "cos_df.corr(method=\"kendall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eligible-awareness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error of cos_sim_ref_hyp in regards to the z-score: 0.7505428608912943\n",
      "Mean Absolute Error of cos_sim_src_ref in regards to the z-score: 0.8685112112028813\n",
      "Mean Absolute Error of cos_sim_src_hyp in regards to the z-score: 0.8435137708922917\n"
     ]
    }
   ],
   "source": [
    "# Mean Absolute Deviation of each of these.\n",
    "for col in cos_df.columns[:3]:\n",
    "    print(f\"Mean Absolute Error of {col} in regards to the z-score: {mean_absolute_error(cos_df[col],cos_df['z-score'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-bloom",
   "metadata": {},
   "source": [
    "---\n",
    "Linear Regression <br>to try and predict avg score based on the cos similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "likely-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cos_df.drop(columns='z-score')\n",
    "y = cos_df['z-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "heavy-access",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "interstate-board",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5779222658053401\n",
      "0.5857079428485272\n",
      "0.6184520926808259\n",
      "0.6078207010586433\n",
      "0.7768129689038648\n",
      "0.5612979583250219\n",
      "0.5852983467641449\n",
      "0.6135030256824922\n",
      "0.5922014643887218\n",
      "0.6984563470021806\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 10)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    lin_model.fit(X_train,y_train)\n",
    "    y_pred = lin_model.predict(X_val)\n",
    "    lin_model_3_mae = mean_absolute_error(y_val,y_pred)\n",
    "    print(lin_model_3_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "minute-pregnancy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.017747794267827563, 0.5008850510604128, -0.047184819744446126, -0.1253158772010228]\n"
     ]
    }
   ],
   "source": [
    "lin_model_3_par = [lin_model.intercept_]\n",
    "lin_model_3_par.extend([coef for coef in lin_model.coef_])\n",
    "print(lin_model_3_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "frequent-species",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44586422378085433 pearson\n",
      "0.30368876066894357 kendall\n"
     ]
    }
   ],
   "source": [
    "# Check the corr of this model. \n",
    "lin_3_pred = cos_df.apply(lambda x: lin_model_3_par[0] + lin_model_3_par[1]*x[0] + lin_model_3_par[2]*x[1] + lin_model_3_par[3]*x[2],axis=1)\n",
    "lin_3_corr_p = lin_3_pred.corr(df1[\"z-score\"], method=\"pearson\")\n",
    "lin_3_corr_k = lin_3_pred.corr(df1[\"z-score\"], method=\"kendall\")\n",
    "print(str(lin_3_corr_p)+\" pearson\")\n",
    "print(str(lin_3_corr_k)+\" kendall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "overhead-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A model with src_ref and src_hyp only. \n",
    "X = cos_df.drop(columns=['cos_sim_ref_hyp','z-score'])\n",
    "y = cos_df['z-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "congressional-patient",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6208575338875748\n",
      "0.6397308062238354\n",
      "0.6666137729859257\n",
      "0.658962972318979\n",
      "0.8436010303091502\n",
      "0.6241674982128292\n",
      "0.6509860838716531\n",
      "0.6721840501001044\n",
      "0.654924047298013\n",
      "0.7494366317731082\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 10)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    lin_model.fit(X_train,y_train)\n",
    "    y_pred = lin_model.predict(X_val)\n",
    "    print(mean_absolute_error(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adjusted-stations",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24608331, 0.09961482, 0.12248068, ..., 0.34918741, 0.20155448,\n",
       "       0.00794485])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cellular-basic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01808070832084239, 0.01802516155853481, 0.23009733373077312]\n"
     ]
    }
   ],
   "source": [
    "lin_model_2_par = [lin_model.intercept_]\n",
    "lin_model_2_par.extend([coef for coef in lin_model.coef_])\n",
    "print(lin_model_2_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "funky-harrison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21652616256543797 pearson\n",
      "0.21652616256543797 kendall\n"
     ]
    }
   ],
   "source": [
    "# Check the corr of this model. \n",
    "lin_2_pred = cos_df.apply(lambda x: lin_model_2_par[0] + lin_model_2_par[1]*x[0] + lin_model_2_par[2]*x[1],axis=1)\n",
    "lin_2_corr_p = lin_2_pred.corr(df1[\"z-score\"])\n",
    "lin_2_corr_k = lin_2_pred.corr(df1[\"z-score\"],method=\"kendall\")\n",
    "print(str(lin_2_corr_p)+\" pearson\")\n",
    "print(str(lin_2_corr_p)+\" kendall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-fellowship",
   "metadata": {},
   "source": [
    "---\n",
    "Using a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "native-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model = MLPRegressor(hidden_layer_sizes=(2,2),max_iter=250,learning_rate_init=0.0015,solver=\"lbfgs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "upper-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "tutorial-decision",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "immune-straight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loss: 0.3441028392724287\n",
      "The MAE is 0.6828216373388843\n",
      "Model loss: 0.34475682667418267\n",
      "The MAE is 0.6649259172575942\n",
      "Model loss: 0.34657736411580903\n",
      "The MAE is 0.6771364437920069\n",
      "Model loss: 0.3501870267445633\n",
      "The MAE is 0.6717719562412185\n",
      "Model loss: 0.3481556787963551\n",
      "The MAE is 0.6681649805295131\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(5)\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    kf_X_train, X_val = X_train[train_index], X_train[val_index]\n",
    "    kf_y_train, y_val = y_train.iloc[train_index], y_train.iloc[val_index]    \n",
    "    \n",
    "    MLP_model.fit(kf_X_train,kf_y_train)\n",
    "    y_val_pred = MLP_model.predict(X_val)\n",
    "    print(f\"Model loss: {MLP_model.loss_}\")\n",
    "    print(f\"The MAE is {mean_absolute_error(y_val,y_val_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-subcommittee",
   "metadata": {},
   "source": [
    "---\n",
    "Using Neural Networks, directly on the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "uniform-shadow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An input has to be of shape (3,1024), because we have 3 embedded vectors of size 1024.\n",
    "# combined array\n",
    "#full_arr = np.dstack((source_arr,refer_arr,trans_arr))\n",
    "\n",
    "# Option 2, make it size (1,2048), by concatenating the arrays. This is what we are using now, according to teacher's indications.\n",
    "full_arr_c = np.concatenate((refer_arr,trans_arr),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "deadly-union",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full_arr_c.copy()\n",
    "y = df1[\"z-score\"].to_numpy()\n",
    "\n",
    "# Train test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "advanced-tolerance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10426, 2048)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "lined-buffalo",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(1024,activation=\"relu\",input_dim=X_train.shape[1]))\n",
    "model.add(layers.Dense(512,activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(128,activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(64,activation=\"relu\"))\n",
    "\n",
    "model.add(layers.Dense(1,activation=\"tanh\"))\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=0.002),loss=\"mse\",metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "worst-gazette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,696,961\n",
      "Trainable params: 2,696,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "insured-nightmare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x29bb66dd4a8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit. Batch Size < > Learning Rate\n",
    "\n",
    "model.fit(X_train,y_train,epochs=50,batch_size=64,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "latter-migration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1159/1159 [==============================] - 1s 478us/step\n",
      "Test MSE: 0.6632.\n",
      "Test MAE: 0.6200.\n",
      "Pearson correlation between y_val_predicted and actual y_val: 0.4257\n"
     ]
    }
   ],
   "source": [
    "# Evaluation and comparison.\n",
    "test_mse,test_mae = model.evaluate(X_test,y_test)\n",
    "test_corr = np.corrcoef(model.predict(X_test).flatten(),y_test)[0][1]\n",
    "print(f\"Test MSE: {test_mse:.4f}.\\nTest MAE: {test_mae:.4f}.\")\n",
    "print(f\"Pearson correlation between y_val_predicted and actual y_val: {test_corr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "typical-wildlife",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error of cos_sim_ref_hyp in regards to the z-score: 0.7505428608912943\n",
      "Mean Absolute Error of cos_sim_src_ref in regards to the z-score: 0.8685112112028813\n",
      "Mean Absolute Error of cos_sim_src_hyp in regards to the z-score: 0.8435137708922917\n"
     ]
    }
   ],
   "source": [
    "# For reference, pt.2\n",
    "for col in cos_df.columns[:3]:\n",
    "    print(f\"Mean Absolute Error of {col} in regards to the z-score: {mean_absolute_error(cos_df[col],cos_df['z-score'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "relative-disposition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation of cos_sim\n",
      "cos_sim_ref_hyp    0.430993\n",
      "cos_sim_src_ref    0.193411\n",
      "cos_sim_src_hyp    0.279916\n",
      "z-score            1.000000\n",
      "Name: z-score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Pearson correlation of cos_sim\")\n",
    "print(cos_df.corr().iloc[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "opposite-collectible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendall correlation of cos_sim\n",
      "cos_sim_ref_hyp    0.293171\n",
      "cos_sim_src_ref    0.134352\n",
      "cos_sim_src_hyp    0.178779\n",
      "z-score            1.000000\n",
      "Name: z-score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Kendall correlation of cos_sim\")\n",
    "print(cos_df.corr(method=\"kendall\").iloc[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "corporate-easter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model with the 3 cos_similarities, pearson: 0.44586422378085433\n",
      "Linear Model with the 3 cos_similarities, kendall: 0.30368876066894357\n",
      "Linear Model with the 2 (src_ref and src_hyp) cos_similarities, pearson: 0.21652616256543797\n",
      "Linear Model with the 2 (src_ref and src_hyp) cos_similarities, kendall: 0.15064035891872554\n"
     ]
    }
   ],
   "source": [
    "# Corr of linear models on cos_sim\n",
    "print(f\"Linear Model with the 3 cos_similarities, pearson: {lin_3_corr_p}\")\n",
    "print(f\"Linear Model with the 3 cos_similarities, kendall: {lin_3_corr_k}\")\n",
    "print(f\"Linear Model with the 2 (src_ref and src_hyp) cos_similarities, pearson: {lin_2_corr_p}\")\n",
    "print(f\"Linear Model with the 2 (src_ref and src_hyp) cos_similarities, kendall: {lin_2_corr_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "tired-diana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model.\n",
    "model.save(\"cs_en_laser_model__testcorr_{:.4f}_MAE_{:.4f}_time{}.h5\".format(test_corr,test_mae,datetime.now().strftime('%d_%m_%H_%M')\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-gibraltar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-amendment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
