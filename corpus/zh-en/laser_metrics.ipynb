{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "editorial-cartridge",
   "metadata": {},
   "source": [
    "Implementation of LASER to the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "universal-haiti",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-removal",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "conceptual-element",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "practical-treasurer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21704 entries, 0 to 21703\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   source       21704 non-null  object \n",
      " 1   reference    21704 non-null  object \n",
      " 2   translation  21704 non-null  object \n",
      " 3   z-score      21704 non-null  float64\n",
      " 4   avg-score    21704 non-null  float64\n",
      " 5   annotators   21704 non-null  int64  \n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 1017.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "tested-float",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ihr Zeitlupentempo maßen sie, als sie vor Spit...</td>\n",
       "      <td>Her timeless pace measures them when they equi...</td>\n",
       "      <td>Their slow speed was measured by researchers o...</td>\n",
       "      <td>-0.345024</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Er sagte, dass die Bereiche ruhige Treffpunkte...</td>\n",
       "      <td>He said the areas offer quiet meeting points b...</td>\n",
       "      <td>He said the spaces provided calm meeting point...</td>\n",
       "      <td>0.903800</td>\n",
       "      <td>97.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Für die Geschäftsleute an der B 27 ist es nur ...</td>\n",
       "      <td>For businessmen at the B 27, it's only a small...</td>\n",
       "      <td>This is only a small consolation for businesse...</td>\n",
       "      <td>0.700503</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diese Fähigkeit sei möglicherweise angeboren o...</td>\n",
       "      <td>This ability may be born or developed with gen...</td>\n",
       "      <td>This ability may be innate, or may develop as ...</td>\n",
       "      <td>-1.256572</td>\n",
       "      <td>51.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Weil sie Wassertemperaturen um die sechs Grad ...</td>\n",
       "      <td>Because they prefer water temperatures around ...</td>\n",
       "      <td>They generally only come to the surface in win...</td>\n",
       "      <td>0.293909</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Ihr Zeitlupentempo maßen sie, als sie vor Spit...   \n",
       "1  Er sagte, dass die Bereiche ruhige Treffpunkte...   \n",
       "2  Für die Geschäftsleute an der B 27 ist es nur ...   \n",
       "3  Diese Fähigkeit sei möglicherweise angeboren o...   \n",
       "4  Weil sie Wassertemperaturen um die sechs Grad ...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Her timeless pace measures them when they equi...   \n",
       "1  He said the areas offer quiet meeting points b...   \n",
       "2  For businessmen at the B 27, it's only a small...   \n",
       "3  This ability may be born or developed with gen...   \n",
       "4  Because they prefer water temperatures around ...   \n",
       "\n",
       "                                         translation   z-score  avg-score  \\\n",
       "0  Their slow speed was measured by researchers o... -0.345024       76.0   \n",
       "1  He said the spaces provided calm meeting point...  0.903800       97.5   \n",
       "2  This is only a small consolation for businesse...  0.700503       94.0   \n",
       "3  This ability may be innate, or may develop as ... -1.256572       51.5   \n",
       "4  They generally only come to the surface in win...  0.293909       87.0   \n",
       "\n",
       "   annotators  \n",
       "0           1  \n",
       "1           2  \n",
       "2           1  \n",
       "3           2  \n",
       "4           2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-affiliate",
   "metadata": {},
   "source": [
    "Comparison of LASER embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fiscal-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_arr = np.load(\"laser.source_embeds.npy\")\n",
    "refer_arr = np.load(\"laser.reference_embeds.npy\")\n",
    "trans_arr = np.load(\"laser.translation_embeds.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-honduras",
   "metadata": {},
   "source": [
    "Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "removed-writing",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_similarity_ref_hyp = []\n",
    "cos_similarity_src_ref = []\n",
    "cos_similarity_src_hyp = []\n",
    "\n",
    "# for each of the cos similarity, put them into lists.\n",
    "for i in range(refer_arr.shape[0]):\n",
    "    cos_similarity_ref_hyp.append((spatial.distance.cosine(refer_arr[i],trans_arr[i])*-1)+1)\n",
    "    cos_similarity_src_ref.append((spatial.distance.cosine(source_arr[i],refer_arr[i])*-1)+1)\n",
    "    cos_similarity_src_hyp.append((spatial.distance.cosine(source_arr[i],trans_arr[i])*-1)+1)\n",
    "\n",
    "\n",
    "# Standardize and transform into series.\n",
    "scaler = StandardScaler()\n",
    "cs_rh = pd.Series(scaler.fit_transform(np.array(cos_similarity_ref_hyp).reshape(-1,1)).flatten(),name=\"cos_sim_ref_hyp\")\n",
    "cs_sr = pd.Series(scaler.fit_transform(np.array(cos_similarity_src_ref).reshape(-1,1)).flatten(),name=\"cos_sim_src_ref\")\n",
    "cs_sh = pd.Series(scaler.fit_transform(np.array(cos_similarity_src_hyp).reshape(-1,1)).flatten(),name=\"cos_sim_src_hyp\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "explicit-frequency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cos_sim_ref_hyp</th>\n",
       "      <th>cos_sim_src_ref</th>\n",
       "      <th>cos_sim_src_hyp</th>\n",
       "      <th>z-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.250038</td>\n",
       "      <td>-0.422368</td>\n",
       "      <td>-1.306007</td>\n",
       "      <td>-0.345024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.048153</td>\n",
       "      <td>0.533522</td>\n",
       "      <td>0.774393</td>\n",
       "      <td>0.903800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.678580</td>\n",
       "      <td>0.130823</td>\n",
       "      <td>0.188789</td>\n",
       "      <td>0.700503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.987798</td>\n",
       "      <td>0.273078</td>\n",
       "      <td>-0.873894</td>\n",
       "      <td>-1.256572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.938938</td>\n",
       "      <td>0.782586</td>\n",
       "      <td>-1.083445</td>\n",
       "      <td>0.293909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21699</th>\n",
       "      <td>1.080071</td>\n",
       "      <td>1.100543</td>\n",
       "      <td>1.362532</td>\n",
       "      <td>1.246459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21700</th>\n",
       "      <td>1.183931</td>\n",
       "      <td>-0.374398</td>\n",
       "      <td>0.015242</td>\n",
       "      <td>0.792878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21701</th>\n",
       "      <td>0.670196</td>\n",
       "      <td>0.637920</td>\n",
       "      <td>0.668873</td>\n",
       "      <td>0.597068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21702</th>\n",
       "      <td>0.720476</td>\n",
       "      <td>-0.220658</td>\n",
       "      <td>0.773841</td>\n",
       "      <td>-0.305719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21703</th>\n",
       "      <td>1.140419</td>\n",
       "      <td>0.545205</td>\n",
       "      <td>1.244882</td>\n",
       "      <td>0.995212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21704 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cos_sim_ref_hyp  cos_sim_src_ref  cos_sim_src_hyp   z-score\n",
       "0            -1.250038        -0.422368        -1.306007 -0.345024\n",
       "1             1.048153         0.533522         0.774393  0.903800\n",
       "2            -0.678580         0.130823         0.188789  0.700503\n",
       "3            -0.987798         0.273078        -0.873894 -1.256572\n",
       "4            -0.938938         0.782586        -1.083445  0.293909\n",
       "...                ...              ...              ...       ...\n",
       "21699         1.080071         1.100543         1.362532  1.246459\n",
       "21700         1.183931        -0.374398         0.015242  0.792878\n",
       "21701         0.670196         0.637920         0.668873  0.597068\n",
       "21702         0.720476        -0.220658         0.773841 -0.305719\n",
       "21703         1.140419         0.545205         1.244882  0.995212\n",
       "\n",
       "[21704 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_df = pd.concat([cs_rh,cs_sr,cs_sh,df1.loc[:,\"z-score\"]],axis=1)\n",
    "cos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "interesting-african",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise Pearson\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cos_sim_ref_hyp</th>\n",
       "      <th>cos_sim_src_ref</th>\n",
       "      <th>cos_sim_src_hyp</th>\n",
       "      <th>z-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cos_sim_ref_hyp</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.618973</td>\n",
       "      <td>0.797330</td>\n",
       "      <td>0.316523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_sim_src_ref</th>\n",
       "      <td>0.618973</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.692192</td>\n",
       "      <td>0.182758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_sim_src_hyp</th>\n",
       "      <td>0.797330</td>\n",
       "      <td>0.692192</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.195875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z-score</th>\n",
       "      <td>0.316523</td>\n",
       "      <td>0.182758</td>\n",
       "      <td>0.195875</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 cos_sim_ref_hyp  cos_sim_src_ref  cos_sim_src_hyp   z-score\n",
       "cos_sim_ref_hyp         1.000000         0.618973         0.797330  0.316523\n",
       "cos_sim_src_ref         0.618973         1.000000         0.692192  0.182758\n",
       "cos_sim_src_hyp         0.797330         0.692192         1.000000  0.195875\n",
       "z-score                 0.316523         0.182758         0.195875  1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pearson\n",
    "print(\"Pairwise Pearson\")\n",
    "cos_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "handmade-couple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise Kendall\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cos_sim_ref_hyp</th>\n",
       "      <th>cos_sim_src_ref</th>\n",
       "      <th>cos_sim_src_hyp</th>\n",
       "      <th>z-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cos_sim_ref_hyp</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.435721</td>\n",
       "      <td>0.608597</td>\n",
       "      <td>0.223125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_sim_src_ref</th>\n",
       "      <td>0.435721</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.540446</td>\n",
       "      <td>0.118914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_sim_src_hyp</th>\n",
       "      <td>0.608597</td>\n",
       "      <td>0.540446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.130874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z-score</th>\n",
       "      <td>0.223125</td>\n",
       "      <td>0.118914</td>\n",
       "      <td>0.130874</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 cos_sim_ref_hyp  cos_sim_src_ref  cos_sim_src_hyp   z-score\n",
       "cos_sim_ref_hyp         1.000000         0.435721         0.608597  0.223125\n",
       "cos_sim_src_ref         0.435721         1.000000         0.540446  0.118914\n",
       "cos_sim_src_hyp         0.608597         0.540446         1.000000  0.130874\n",
       "z-score                 0.223125         0.118914         0.130874  1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kendall\n",
    "print(\"Pairwise Kendall\")\n",
    "cos_df.corr(method=\"kendall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "parliamentary-influence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise Spearman\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cos_sim_ref_hyp</th>\n",
       "      <th>cos_sim_src_ref</th>\n",
       "      <th>cos_sim_src_hyp</th>\n",
       "      <th>z-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cos_sim_ref_hyp</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.604819</td>\n",
       "      <td>0.787616</td>\n",
       "      <td>0.326655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_sim_src_ref</th>\n",
       "      <td>0.604819</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.723731</td>\n",
       "      <td>0.176150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_sim_src_hyp</th>\n",
       "      <td>0.787616</td>\n",
       "      <td>0.723731</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.193575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z-score</th>\n",
       "      <td>0.326655</td>\n",
       "      <td>0.176150</td>\n",
       "      <td>0.193575</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 cos_sim_ref_hyp  cos_sim_src_ref  cos_sim_src_hyp   z-score\n",
       "cos_sim_ref_hyp         1.000000         0.604819         0.787616  0.326655\n",
       "cos_sim_src_ref         0.604819         1.000000         0.723731  0.176150\n",
       "cos_sim_src_hyp         0.787616         0.723731         1.000000  0.193575\n",
       "z-score                 0.326655         0.176150         0.193575  1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spearman\n",
    "print(\"Pairwise Spearman\")\n",
    "cos_df.corr(method=\"spearman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "unlimited-aurora",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error of cos_sim_ref_hyp in regards to the z-score: 0.8128335093539766\n",
      "Mean Absolute Error of cos_sim_src_ref in regards to the z-score: 0.8796000501264563\n",
      "Mean Absolute Error of cos_sim_src_hyp in regards to the z-score: 0.8861561012422285\n"
     ]
    }
   ],
   "source": [
    "# Mean Absolute Deviation of each of these.\n",
    "for col in cos_df.columns[:3]:\n",
    "    print(f\"Mean Absolute Error of {col} in regards to the z-score: {mean_absolute_error(cos_df[col],cos_df['z-score'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-deadline",
   "metadata": {},
   "source": [
    "---\n",
    "Linear Regression <br>to try and predict avg score based on the cos similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "daily-conservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cos_df.drop(columns='z-score')\n",
    "y = cos_df['z-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "minus-prize",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "funded-nudist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6527408819767678\n",
      "0.6757954960873159\n",
      "0.6668912096850256\n",
      "0.6452570374362728\n",
      "0.6109181224425928\n",
      "0.6440656783167589\n",
      "0.5899620045423257\n",
      "0.6368125210787335\n",
      "0.6355302938729582\n",
      "0.6398936072186637\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 10)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    lin_model.fit(X_train,y_train)\n",
    "    y_pred = lin_model.predict(X_val)\n",
    "    print(mean_absolute_error(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "accepting-monroe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.37602588  0.03522878 -0.16227454]\n",
      "-0.004071303295636321\n"
     ]
    }
   ],
   "source": [
    "print(lin_model.coef_)\n",
    "print(lin_model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "standing-lucas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A model with src_ref and src_hyp only. \n",
    "X = cos_df.drop(columns=['cos_sim_ref_hyp','z-score'])\n",
    "y = cos_df['z-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dramatic-confusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6872387987829903\n",
      "0.7074090038492186\n",
      "0.7017583072988852\n",
      "0.6806976681436335\n",
      "0.648423808347745\n",
      "0.6688137843687497\n",
      "0.6230586532258409\n",
      "0.6679940901556314\n",
      "0.6562495683670608\n",
      "0.6630161471191572\n",
      "[0.08666064 0.10156855]\n",
      "-0.007630570925880059\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 10)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    lin_model.fit(X_train,y_train)\n",
    "    y_pred = lin_model.predict(X_val)\n",
    "    print(mean_absolute_error(y_val,y_pred))\n",
    "print(lin_model.coef_)\n",
    "print(lin_model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-advisory",
   "metadata": {},
   "source": [
    "Seems like it is about the same, which I guess does make sense, consdering the correlations between the three are likely to be very strong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "textile-bermuda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.11235052, -0.2473391 ,  0.15787498, ...,  0.11558839,\n",
       "        0.05184496,  0.16605814])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-breath",
   "metadata": {},
   "source": [
    "---\n",
    "Using a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acceptable-museum",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model = MLPRegressor(hidden_layer_sizes=(2,2),max_iter=250,learning_rate_init=0.0015,solver=\"lbfgs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "breathing-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "improved-spine",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ultimate-eating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loss: 0.35149098186082195\n",
      "The MAE is 0.6651126334708947\n",
      "Model loss: 0.34499995194496486\n",
      "The MAE is 0.6690594659385594\n",
      "Model loss: 0.3462728316187285\n",
      "The MAE is 0.6653201811628741\n",
      "Model loss: 0.36655920241579554\n",
      "The MAE is 0.6734308556282601\n",
      "Model loss: 0.3436349927514222\n",
      "The MAE is 0.6684407059066011\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(5)\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    kf_X_train, X_val = X_train[train_index], X_train[val_index]\n",
    "    kf_y_train, y_val = y_train.iloc[train_index], y_train.iloc[val_index]    \n",
    "    \n",
    "    MLP_model.fit(kf_X_train,kf_y_train)\n",
    "    y_val_pred = MLP_model.predict(X_val)\n",
    "    print(f\"Model loss: {MLP_model.loss_}\")\n",
    "    print(f\"The MAE is {mean_absolute_error(y_val,y_val_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-imaging",
   "metadata": {},
   "source": [
    "---\n",
    "Using Neural Networks, directly on the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "competent-dynamics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An input has to be of shape (3,1024), because we have 3 embedded vectors of size 1024.\n",
    "# combined array\n",
    "#full_arr = np.dstack((source_arr,refer_arr,trans_arr))\n",
    "\n",
    "# Option 2, make it size (1,2048), by concatenating the arrays. This is what we are using now, according to teacher's indications.\n",
    "full_arr_c = np.concatenate((refer_arr,trans_arr),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "studied-horror",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full_arr_c.copy()\n",
    "y = df1[\"z-score\"].to_numpy()\n",
    "\n",
    "# Train test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "divine-ultimate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19533, 2048)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "regular-bennett",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown activation function:gelu",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-dcb8ad9b6376>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gelu\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gelu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\keras\\layers\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[0;32m    873\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 875\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    876\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_initializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitializers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\keras\\activations.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(identifier)\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[0midentifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\keras\\activations.py\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(name, custom_objects)\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[0mmodule_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         printable_module_name='activation function')\n\u001b[0m\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m                 raise ValueError('Unknown ' + printable_module_name +\n\u001b[1;32m--> 167\u001b[1;33m                                  ':' + function_name)\n\u001b[0m\u001b[0;32m    168\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown activation function:gelu"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(1024,activation=\"gelu\",input_dim=X_train.shape[1]))\n",
    "model.add(layers.Dense(512,activation=\"gelu\"))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(128,activation=\"gelu\"))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(64,activation=\"gelu\"))\n",
    "\n",
    "model.add(layers.Dense(1,activation=\"tanh\"))\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=0.002),loss=\"mse\",metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "verified-genealogy",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling build() or calling fit() with some data. Or specify input_shape or batch_input_shape in the first layer for automatic build. ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m   1318\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m             raise ValueError(\n\u001b[1;32m-> 1320\u001b[1;33m                 \u001b[1;34m'This model has not yet been built. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1321\u001b[0m                 \u001b[1;34m'Build the model first by calling build() '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m                 \u001b[1;34m'or calling fit() with some data. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling build() or calling fit() with some data. Or specify input_shape or batch_input_shape in the first layer for automatic build. "
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cooperative-determination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x23707aae2e8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit. Batch Size < > Learning Rate\n",
    "\n",
    "model.fit(X_train,y_train,epochs=50,batch_size=64,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "intense-column",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile a model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-8d272dc0bd6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Evaluation and comparison.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtest_mse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_mae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Test MSE: {test_mse:.4f}.\\nTest MAE: {test_mae:.4f}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Pearson correlation between y_val_predicted and actual y_val: {np.corrcoef(model.predict(X_test).flatten(),y_test)[0][1]:.4f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1347\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1348\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1349\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1350\u001b[0m         \u001b[1;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1351\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    506\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m                 raise RuntimeError('You must compile a model before '\n\u001b[0m\u001b[0;32m    509\u001b[0m                                    \u001b[1;34m'training/testing. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m                                    'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You must compile a model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "# Evaluation and comparison.\n",
    "test_mse,test_mae = model.evaluate(X_test,y_test)\n",
    "print(f\"Test MSE: {test_mse:.4f}.\\nTest MAE: {test_mae:.4f}.\")\n",
    "print(f\"Pearson correlation between y_val_predicted and actual y_val: {np.corrcoef(model.predict(X_test).flatten(),y_test)[0][1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "reduced-suffering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model.\n",
    "model.save(\"de_en_laser_model_MAE_{:.4f}_time{}.h5\".format(test_mae,datetime.now().strftime('%d_%m_%H_%M')\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-voluntary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-hawaii",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
