{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "forced-stand",
   "metadata": {},
   "source": [
    "### Implementation of LASER to the corpus\n",
    "### RU-EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ongoing-democrat",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-muslim",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "opposed-gravity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dress-flush",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17980 entries, 0 to 17979\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   source       17980 non-null  object \n",
      " 1   reference    17980 non-null  object \n",
      " 2   translation  17980 non-null  object \n",
      " 3   z-score      17980 non-null  float64\n",
      " 4   avg-score    17980 non-null  float64\n",
      " 5   annotators   17980 non-null  int64  \n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 842.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "artistic-oxide",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В этом году крымчане получат уведомление на оп...</td>\n",
       "      <td>This year the Crimeans will receive a notice f...</td>\n",
       "      <td>This year, residents of Crimea will receive a ...</td>\n",
       "      <td>0.878043</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Энергетические компании находятся под давление...</td>\n",
       "      <td>Energy companies are under pressure due to low...</td>\n",
       "      <td>Energy companies are under pressure from lower...</td>\n",
       "      <td>0.511473</td>\n",
       "      <td>81.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>В бархатный сезон покупают туры в основном оди...</td>\n",
       "      <td>In the velvet season, tours are mostly single ...</td>\n",
       "      <td>In the autumn season, tours are mainly purchas...</td>\n",
       "      <td>0.947866</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Возле него на всякий случай стоит познавательн...</td>\n",
       "      <td>Near him, just in case, there is a cognitive t...</td>\n",
       "      <td>Beside it, for good measure, there is an infor...</td>\n",
       "      <td>1.052601</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Действительно ли Эфиопия находится на грани ра...</td>\n",
       "      <td>Is Ethiopia on the verge of schism?</td>\n",
       "      <td>Is Ethiopia about to crack?</td>\n",
       "      <td>0.738397</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  В этом году крымчане получат уведомление на оп...   \n",
       "1  Энергетические компании находятся под давление...   \n",
       "2  В бархатный сезон покупают туры в основном оди...   \n",
       "3  Возле него на всякий случай стоит познавательн...   \n",
       "4  Действительно ли Эфиопия находится на грани ра...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  This year the Crimeans will receive a notice f...   \n",
       "1  Energy companies are under pressure due to low...   \n",
       "2  In the velvet season, tours are mostly single ...   \n",
       "3  Near him, just in case, there is a cognitive t...   \n",
       "4                Is Ethiopia on the verge of schism?   \n",
       "\n",
       "                                         translation   z-score  avg-score  \\\n",
       "0  This year, residents of Crimea will receive a ...  0.878043       92.0   \n",
       "1  Energy companies are under pressure from lower...  0.511473       81.5   \n",
       "2  In the autumn season, tours are mainly purchas...  0.947866       94.0   \n",
       "3  Beside it, for good measure, there is an infor...  1.052601       97.0   \n",
       "4                        Is Ethiopia about to crack?  0.738397       88.0   \n",
       "\n",
       "   annotators  \n",
       "0           1  \n",
       "1           2  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-classics",
   "metadata": {},
   "source": [
    "Comparison of LASER embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "included-investigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_arr = np.load(\"laser.source_embeds.npy\")\n",
    "refer_arr = np.load(\"laser.reference_embeds.npy\")\n",
    "trans_arr = np.load(\"laser.translation_embeds.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-container",
   "metadata": {},
   "source": [
    "Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mathematical-associate",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_similarity_ref_hyp = []\n",
    "cos_similarity_src_ref = []\n",
    "cos_similarity_src_hyp = []\n",
    "\n",
    "# for each of the cos similarity, put them into lists.\n",
    "for i in range(refer_arr.shape[0]):\n",
    "    cos_similarity_ref_hyp.append((spatial.distance.cosine(refer_arr[i],trans_arr[i])*-1)+1)\n",
    "    cos_similarity_src_ref.append((spatial.distance.cosine(source_arr[i],refer_arr[i])*-1)+1)\n",
    "    cos_similarity_src_hyp.append((spatial.distance.cosine(source_arr[i],trans_arr[i])*-1)+1)\n",
    "\n",
    "\n",
    "# Standardize and transform into series.\n",
    "scaler = StandardScaler()\n",
    "cs_rh = pd.Series(scaler.fit_transform(np.array(cos_similarity_ref_hyp).reshape(-1,1)).flatten(),name=\"cos_sim_ref_hyp\")\n",
    "cs_sr = pd.Series(scaler.fit_transform(np.array(cos_similarity_src_ref).reshape(-1,1)).flatten(),name=\"cos_sim_src_ref\")\n",
    "cs_sh = pd.Series(scaler.fit_transform(np.array(cos_similarity_src_hyp).reshape(-1,1)).flatten(),name=\"cos_sim_src_hyp\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "velvet-wrong",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cos_sim_ref_hyp</th>\n",
       "      <th>cos_sim_src_ref</th>\n",
       "      <th>cos_sim_src_hyp</th>\n",
       "      <th>z-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.090981</td>\n",
       "      <td>0.645514</td>\n",
       "      <td>0.332329</td>\n",
       "      <td>0.878043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.196355</td>\n",
       "      <td>0.525212</td>\n",
       "      <td>0.096179</td>\n",
       "      <td>0.511473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.341700</td>\n",
       "      <td>-0.945737</td>\n",
       "      <td>-0.372678</td>\n",
       "      <td>0.947866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.203153</td>\n",
       "      <td>-0.493851</td>\n",
       "      <td>0.479380</td>\n",
       "      <td>1.052601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.214009</td>\n",
       "      <td>-1.498225</td>\n",
       "      <td>-2.165453</td>\n",
       "      <td>0.738397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cos_sim_ref_hyp  cos_sim_src_ref  cos_sim_src_hyp   z-score\n",
       "0         0.090981         0.645514         0.332329  0.878043\n",
       "1        -0.196355         0.525212         0.096179  0.511473\n",
       "2        -0.341700        -0.945737        -0.372678  0.947866\n",
       "3        -0.203153        -0.493851         0.479380  1.052601\n",
       "4        -2.214009        -1.498225        -2.165453  0.738397"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_df = pd.concat([cs_rh,cs_sr,cs_sh,df1.loc[:,\"z-score\"]],axis=1)\n",
    "cos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "competitive-speaker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise Pearson\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cos_sim_ref_hyp</th>\n",
       "      <th>cos_sim_src_ref</th>\n",
       "      <th>cos_sim_src_hyp</th>\n",
       "      <th>z-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cos_sim_ref_hyp</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.631136</td>\n",
       "      <td>0.741079</td>\n",
       "      <td>0.342903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_sim_src_ref</th>\n",
       "      <td>0.631136</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.721308</td>\n",
       "      <td>0.195572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_sim_src_hyp</th>\n",
       "      <td>0.741079</td>\n",
       "      <td>0.721308</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.195184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z-score</th>\n",
       "      <td>0.342903</td>\n",
       "      <td>0.195572</td>\n",
       "      <td>0.195184</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 cos_sim_ref_hyp  cos_sim_src_ref  cos_sim_src_hyp   z-score\n",
       "cos_sim_ref_hyp         1.000000         0.631136         0.741079  0.342903\n",
       "cos_sim_src_ref         0.631136         1.000000         0.721308  0.195572\n",
       "cos_sim_src_hyp         0.741079         0.721308         1.000000  0.195184\n",
       "z-score                 0.342903         0.195572         0.195184  1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pearson\n",
    "print(\"Pairwise Pearson\")\n",
    "cos_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "frozen-frost",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise Kendall\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cos_sim_ref_hyp</th>\n",
       "      <th>cos_sim_src_ref</th>\n",
       "      <th>cos_sim_src_hyp</th>\n",
       "      <th>z-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cos_sim_ref_hyp</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.399261</td>\n",
       "      <td>0.544460</td>\n",
       "      <td>0.236634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_sim_src_ref</th>\n",
       "      <td>0.399261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.546191</td>\n",
       "      <td>0.116234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_sim_src_hyp</th>\n",
       "      <td>0.544460</td>\n",
       "      <td>0.546191</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.118514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z-score</th>\n",
       "      <td>0.236634</td>\n",
       "      <td>0.116234</td>\n",
       "      <td>0.118514</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 cos_sim_ref_hyp  cos_sim_src_ref  cos_sim_src_hyp   z-score\n",
       "cos_sim_ref_hyp         1.000000         0.399261         0.544460  0.236634\n",
       "cos_sim_src_ref         0.399261         1.000000         0.546191  0.116234\n",
       "cos_sim_src_hyp         0.544460         0.546191         1.000000  0.118514\n",
       "z-score                 0.236634         0.116234         0.118514  1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kendall\n",
    "print(\"Pairwise Kendall\")\n",
    "cos_df.corr(method=\"kendall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "searching-difficulty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error of cos_sim_ref_hyp in regards to the z-score: 0.7842597127484974\n",
      "Mean Absolute Error of cos_sim_src_ref in regards to the z-score: 0.8609030276643188\n",
      "Mean Absolute Error of cos_sim_src_hyp in regards to the z-score: 0.875004989889389\n"
     ]
    }
   ],
   "source": [
    "# Mean Absolute Deviation of each of these.\n",
    "for col in cos_df.columns[:3]:\n",
    "    print(f\"Mean Absolute Error of {col} in regards to the z-score: {mean_absolute_error(cos_df[col],cos_df['z-score'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-eagle",
   "metadata": {},
   "source": [
    "---\n",
    "Linear Regression <br>to try and predict avg score based on the cos similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joined-advertising",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cos_df.drop(columns='z-score')\n",
    "y = cos_df['z-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "parental-cleaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "mental-picking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5960710557562018\n",
      "0.6174259543915787\n",
      "0.6512767939130871\n",
      "0.6551620429389416\n",
      "0.6574396729630018\n",
      "0.6376470406192327\n",
      "0.6008900363054817\n",
      "0.6198715246756239\n",
      "0.712151312874924\n",
      "0.6378996643778573\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 10)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    lin_model.fit(X_train,y_train)\n",
    "    y_pred = lin_model.predict(X_val)\n",
    "    lin_model_3_mae = mean_absolute_error(y_val,y_pred)\n",
    "    print(lin_model_3_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "growing-basis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0034786935062026455, 0.38461416565797896, 0.03342224180059689, -0.13847138238775347]\n"
     ]
    }
   ],
   "source": [
    "lin_model_3_par = [lin_model.intercept_]\n",
    "lin_model_3_par.extend([coef for coef in lin_model.coef_])\n",
    "print(lin_model_3_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "affected-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A model with src_ref and src_hyp only. \n",
    "X = cos_df.drop(columns=['cos_sim_ref_hyp','z-score'])\n",
    "y = cos_df['z-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "suffering-dancing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6667819975210332\n",
      "0.6538828380941704\n",
      "0.6946735070511983\n",
      "0.6983276024198847\n",
      "0.6920425300385376\n",
      "0.6735663057159539\n",
      "0.6448266327638793\n",
      "0.6639671106266699\n",
      "0.7351340916537735\n",
      "0.6734323696134786\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 10)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    lin_model.fit(X_train,y_train)\n",
    "    y_pred = lin_model.predict(X_val)\n",
    "    print(mean_absolute_error(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "incident-wound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05456465, -0.04641414,  0.12301479, ..., -0.34584902,\n",
       "       -0.16493327,  0.00259433])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "extraordinary-roller",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003093191432067345, 0.1122625940476956, 0.09158706022470825]\n"
     ]
    }
   ],
   "source": [
    "lin_model_2_par = [lin_model.intercept_]\n",
    "lin_model_2_par.extend([coef for coef in lin_model.coef_])\n",
    "print(lin_model_2_par)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-thinking",
   "metadata": {},
   "source": [
    "---\n",
    "Using a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "clinical-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model = MLPRegressor(hidden_layer_sizes=(2,2),max_iter=250,learning_rate_init=0.0015,solver=\"lbfgs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "local-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "unnecessary-tender",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ongoing-valley",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loss: 0.3602669013436487\n",
      "The MAE is 0.7080631343328468\n",
      "Model loss: 0.3702645546192668\n",
      "The MAE is 0.6700767657691566\n",
      "Model loss: 0.37060335845093473\n",
      "The MAE is 0.6641719805499471\n",
      "Model loss: 0.37784641724397233\n",
      "The MAE is 0.6655677640072851\n",
      "Model loss: 0.3670488681820223\n",
      "The MAE is 0.6738987995005139\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(5)\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    kf_X_train, X_val = X_train[train_index], X_train[val_index]\n",
    "    kf_y_train, y_val = y_train.iloc[train_index], y_train.iloc[val_index]    \n",
    "    \n",
    "    MLP_model.fit(kf_X_train,kf_y_train)\n",
    "    y_val_pred = MLP_model.predict(X_val)\n",
    "    print(f\"Model loss: {MLP_model.loss_}\")\n",
    "    print(f\"The MAE is {mean_absolute_error(y_val,y_val_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-ladder",
   "metadata": {},
   "source": [
    "---\n",
    "Using Neural Networks, directly on the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "executed-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An input has to be of shape (3,1024), because we have 3 embedded vectors of size 1024.\n",
    "# combined array\n",
    "#full_arr = np.dstack((source_arr,refer_arr,trans_arr))\n",
    "\n",
    "# Option 2, make it size (1,2048), by concatenating the arrays. This is what we are using now, according to teacher's indications.\n",
    "full_arr_c = np.concatenate((refer_arr,trans_arr),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "incredible-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full_arr_c.copy()\n",
    "y = df1[\"z-score\"].to_numpy()\n",
    "\n",
    "# Train test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "structural-parliament",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16182, 2048)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "theoretical-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(1024,activation=\"relu\",input_dim=X_train.shape[1]))\n",
    "model.add(layers.Dense(512,activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(128,activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(64,activation=\"relu\"))\n",
    "\n",
    "model.add(layers.Dense(1,activation=\"tanh\"))\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=0.002),loss=\"mse\",metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "established-manhattan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,696,961\n",
      "Trainable params: 2,696,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-insured",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit. Batch Size < > Learning Rate\n",
    "\n",
    "model.fit(X_train,y_train,epochs=50,batch_size=64,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-startup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation and comparison.\n",
    "test_mse,test_mae = model.evaluate(X_test,y_test)\n",
    "test_corr = np.corrcoef(model.predict(X_test).flatten(),y_test)[0][1]\n",
    "print(f\"Test MSE: {test_mse:.4f}.\\nTest MAE: {test_mae:.4f}.\")\n",
    "print(f\"Pearson correlation between y_val_predicted and actual y_val: {test_corr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-forty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reference, pt.2\n",
    "for col in cos_df.columns[:3]:\n",
    "    print(f\"Mean Absolute Error of {col} in regards to the z-score: {mean_absolute_error(cos_df[col],cos_df['z-score'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-ecuador",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model.\n",
    "model.save(\"ru_en_laser_model__testcorr_{:.4f}_MAE_{:.4f}_time{}.h5\".format(test_corr,test_mae,datetime.now().strftime('%d_%m_%H_%M')\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-picnic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-butterfly",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
