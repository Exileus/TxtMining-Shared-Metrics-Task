{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43d66d4e",
   "metadata": {},
   "source": [
    "# Text Mining Group Project\n",
    "## EN-ZH Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7df445",
   "metadata": {},
   "source": [
    "##### TOC for Implemented Metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ccf850",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0410b2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Installs.\n",
    "#!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54c0b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from rouge import Rouge\n",
    "import string\n",
    "from nltk.translate import chrf_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08abdb7",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4bb3e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e111c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10221 entries, 0 to 10220\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   source       10221 non-null  object \n",
      " 1   reference    10221 non-null  object \n",
      " 2   translation  10221 non-null  object \n",
      " 3   z-score      10221 non-null  float64\n",
      " 4   avg-score    10221 non-null  float64\n",
      " 5   annotators   10221 non-null  int64  \n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 479.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2d6cdfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"In the GISS model's simulation, Venus' slow s...</td>\n",
       "      <td>GSIS的科学家AnthonyDelGenio在新闻稿中解释说：“在GISS模型的模拟模型中...</td>\n",
       "      <td>戈达德太空研究所科学家安东尼·德尔·杰尼奥在新闻发布会上解释说：“在戈达德太空研究所的模型模...</td>\n",
       "      <td>-1.171867</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ai Yanhan of China in the Women's 4 x 200m Fre...</td>\n",
       "      <td>中国在英国女性4x200mFreestreyWTE中的最后被称为：“中国14岁的孩子从球下降...</td>\n",
       "      <td>参加女子4x200米自由泳接力赛决赛的中国小将艾衍含被这样描述：“那名14岁的中国小姑娘犯了...</td>\n",
       "      <td>-2.255403</td>\n",
       "      <td>26.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Then came 2012, when nothing much went right f...</td>\n",
       "      <td>然后来到2012年，当她和她的队友们没有什么好处。</td>\n",
       "      <td>2012年，她和她的队友都不被看好。</td>\n",
       "      <td>-2.508996</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Since last year, Guodian Group has exported a ...</td>\n",
       "      <td>自去年以来，GoudianGroup从南非通过南非港口出口了163套风力发电项目。</td>\n",
       "      <td>自去年以来，国电集团共计有163套风电项目陆续从连云港港出口南非。</td>\n",
       "      <td>-2.416780</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Some alleged that the Kempinski hotel simply \"...</td>\n",
       "      <td>一些人指称，Kempinski旅馆只是\"被捕\"，以满足阿拉伯客户的要求。</td>\n",
       "      <td>有人认为凯宾斯基酒店简直是为了满足阿拉伯客户的要求而“卑躬屈膝”。</td>\n",
       "      <td>-1.489676</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  \"In the GISS model's simulation, Venus' slow s...   \n",
       "1  Ai Yanhan of China in the Women's 4 x 200m Fre...   \n",
       "2  Then came 2012, when nothing much went right f...   \n",
       "3  Since last year, Guodian Group has exported a ...   \n",
       "4  Some alleged that the Kempinski hotel simply \"...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  GSIS的科学家AnthonyDelGenio在新闻稿中解释说：“在GISS模型的模拟模型中...   \n",
       "1  中国在英国女性4x200mFreestreyWTE中的最后被称为：“中国14岁的孩子从球下降...   \n",
       "2                          然后来到2012年，当她和她的队友们没有什么好处。   \n",
       "3          自去年以来，GoudianGroup从南非通过南非港口出口了163套风力发电项目。   \n",
       "4               一些人指称，Kempinski旅馆只是\"被捕\"，以满足阿拉伯客户的要求。   \n",
       "\n",
       "                                         translation   z-score  avg-score  \\\n",
       "0  戈达德太空研究所科学家安东尼·德尔·杰尼奥在新闻发布会上解释说：“在戈达德太空研究所的模型模... -1.171867       50.0   \n",
       "1  参加女子4x200米自由泳接力赛决赛的中国小将艾衍含被这样描述：“那名14岁的中国小姑娘犯了... -2.255403       26.5   \n",
       "2                                 2012年，她和她的队友都不被看好。 -2.508996       21.0   \n",
       "3                  自去年以来，国电集团共计有163套风电项目陆续从连云港港出口南非。 -2.416780       23.0   \n",
       "4                  有人认为凯宾斯基酒店简直是为了满足阿拉伯客户的要求而“卑躬屈膝”。 -1.489676       45.0   \n",
       "\n",
       "   annotators  \n",
       "0           1  \n",
       "1           2  \n",
       "2           1  \n",
       "3           1  \n",
       "4           7  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6215719e",
   "metadata": {},
   "source": [
    "---\n",
    "### PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b969ed29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source\n",
      "Bad idx: []\n",
      "reference\n",
      "Bad idx: []\n",
      "translation\n",
      "Bad idx: []\n"
     ]
    }
   ],
   "source": [
    "# Check for empty or sparse reference / translation, and drop them.\n",
    "# In this case, strings may be very short, so let's just drop those that are empty.\n",
    "for column in [\"source\",\"reference\",\"translation\"]:\n",
    "    print(column)\n",
    "    bad_idx = [idx for idx in np.where(df1[column].str.len()==0)[0]]\n",
    "    print(f\"Bad idx: {bad_idx}\")\n",
    "    df1 = df1.drop(index=bad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d43c536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two dataframes. One is unprocessed, the other is preprocessed to remove punctuation and be lowercased.\n",
    "# (Future note: maybe also remove stopwords?)\n",
    "df_u = df1.copy()\n",
    "df_p = df1.copy()\n",
    "\n",
    "for x in [\"source\",\"reference\",\"translation\"]:\n",
    "    # lowercase.\n",
    "    df_p[x] = df1[x].str.lower()\n",
    "    # Remove punct.\n",
    "    df_p[x] = df1[x].map(lambda s: s.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "                           .lower()\n",
    "                          )\n",
    "    \n",
    "df_dict = {\"df_u\":df_u,\"df_p\":df_p}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a641ab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize a scaler for later.\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4f4474",
   "metadata": {},
   "source": [
    "---\n",
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02762189",
   "metadata": {},
   "source": [
    "## FOR THE CHINESE CHARACTERS WE NEED A SPECIFIC ROUGE ZH, AS WELL AS A SPECIFIC TOKENIZER FOR BLEU.\n",
    "## HOWEVER THIS IS UNLIKELY TO BE BETTER THAN CHRF FOR THIS DATASET DUE TO THE CHARACTER-BASED NATURE OF THE LANGUAGE.\n",
    "### SO I SKIPPED IT FOR NOW.\n",
    "#### HERES A LINK https://github.com/JialeGuo/py_rouge_zh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61df247d",
   "metadata": {},
   "source": [
    "--- \n",
    "Bleu Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22b79680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_first_BLEU(reference,translation):\n",
    "    \"\"\"\n",
    "    Expects lists of strings for both reference and translation.\n",
    "    Returns the score \n",
    "    \"\"\"\n",
    "    \n",
    "    # Let word be every unique word in the translation.\n",
    "    # Can be done by setting up a Counter object.\n",
    "    t_c = Counter(word_tokenize(translation))\n",
    "    words = sorted(t_c)\n",
    "    \n",
    "    refs_c = Counter(word_tokenize(reference))\n",
    "    \n",
    "    # Let Covered be the minimum amt of times a word appears in the reference, compared to R(w).\n",
    "    # Let D(word) be how many times a unique word appears in the candidate translation.\n",
    "    # Let R(word) be the largest numer of times the word appears in any one reference.\n",
    "    \n",
    "    covered = 0\n",
    "    \n",
    "    for word in words:\n",
    "        covered += min(t_c[word],refs_c[word])\n",
    "\n",
    "    \n",
    "\n",
    "    # Let total be the number of words in translation.\n",
    "    total = sum(t_c.values())\n",
    "    \n",
    "    BLEU_score = covered / total\n",
    "    \n",
    "    return BLEU_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e80251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_scores_list = [\"basic bleu\"]\n",
    "\n",
    "for df in list(df_dict.values()):\n",
    "    for key in bleu_scores_list:\n",
    "        # Apply the function to get a column of the scores.\n",
    "        df[(key+\" score\")] = df.apply(lambda row: my_first_BLEU(row[\"reference\"],row[\"translation\"]),axis=1)\n",
    "        # Also add a z score column.\n",
    "        df[(key+ \"_zscore\")] = scaler.fit_transform(df[(key+\" score\")].to_numpy().reshape(-1,1)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2575cd0",
   "metadata": {},
   "source": [
    "---\n",
    "Rouge metric as described in\n",
    "\n",
    "https://towardsdatascience.com/the-ultimate-performance-metric-in-nlp-111df6c64460\n",
    "\n",
    "And\n",
    "https://pypi.org/project/rouge-metric/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c48f64df",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9548a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'f': 0.0, 'p': 0.0, 'r': 0.0},\n",
       "  'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0},\n",
       "  'rouge-l': {'f': 0.0, 'p': 0.0, 'r': 0.0}}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example Cell\n",
    "model_out = df1[\"translation\"][0]\n",
    "reference = df1[\"reference\"][0]\n",
    "# The get scores method returns three metrics, F1 score, p precision and recall r.\n",
    "# For each unigram,bigram and Longest sequence.\n",
    "rouge.get_scores(model_out,reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa0b3e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scores.\n",
    "# For every df considered;\n",
    "for df in list(df_dict.values()):\n",
    "    # For the entire model, model_out and reference need to be lists of strings.\n",
    "    model_out = df[\"translation\"].to_list()\n",
    "    reference = df[\"reference\"].to_list()\n",
    "    rouge_scores = rouge.get_scores(model_out,reference)\n",
    "    # For each of the scores calculated, output a new column in the df with the f1 scores.\n",
    "    for key in rouge_scores[0].keys():\n",
    "        df[(key+\" score\")] = pd.Series([score[key][\"f\"] for score in rouge_scores])\n",
    "        # Also add a z score column.\n",
    "        df[(key+ \"_zscore\")] = scaler.fit_transform(df[(key+\" score\")].to_numpy().reshape(-1,1)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b61891",
   "metadata": {},
   "source": [
    "---\n",
    "#### chrF metric\n",
    "\n",
    "Check the paper here: https://www.aclweb.org/anthology/W15-3049.pdf\n",
    "\n",
    "The general formula for the CHRF score is:\n",
    "\n",
    "`CHRFBeta = (1 + Beta**2) * ((chrP * chrR) / (Beta**2*chrP + chrR))`\n",
    "\n",
    "where:\n",
    "* chrP is the percentage of n-grams in the hypothesis which have a counterpart in the reference.\n",
    "* chrR is the percentage of character n-grams in the reference which are also present in the hypothesis.\n",
    "* Beta is a parameter which assigns beta times more importance to recall than to precision (if beta == 1, they have the same importance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d1aa022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrf_b1_n16</th>\n",
       "      <th>chrf_b3_n16</th>\n",
       "      <th>chrf_b1_n110</th>\n",
       "      <th>chrf_b3_n110</th>\n",
       "      <th>chrf_b1_n26</th>\n",
       "      <th>chrf_b3_n26</th>\n",
       "      <th>chrf_b1_n210</th>\n",
       "      <th>chrf_b3_n210</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.169171</td>\n",
       "      <td>0.179917</td>\n",
       "      <td>0.101503</td>\n",
       "      <td>0.107950</td>\n",
       "      <td>1.118287e-01</td>\n",
       "      <td>1.190255e-01</td>\n",
       "      <td>6.212704e-02</td>\n",
       "      <td>6.612526e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.134180</td>\n",
       "      <td>0.136271</td>\n",
       "      <td>0.080508</td>\n",
       "      <td>0.081762</td>\n",
       "      <td>7.799717e-02</td>\n",
       "      <td>7.923357e-02</td>\n",
       "      <td>4.333176e-02</td>\n",
       "      <td>4.401865e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.370555</td>\n",
       "      <td>0.324404</td>\n",
       "      <td>0.222333</td>\n",
       "      <td>0.194642</td>\n",
       "      <td>3.144338e-01</td>\n",
       "      <td>2.740581e-01</td>\n",
       "      <td>1.746855e-01</td>\n",
       "      <td>1.522545e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.237745</td>\n",
       "      <td>0.218189</td>\n",
       "      <td>0.142647</td>\n",
       "      <td>0.130914</td>\n",
       "      <td>1.717801e-01</td>\n",
       "      <td>1.573495e-01</td>\n",
       "      <td>9.543338e-02</td>\n",
       "      <td>8.741637e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.254548</td>\n",
       "      <td>0.251340</td>\n",
       "      <td>0.190520</td>\n",
       "      <td>0.188031</td>\n",
       "      <td>2.278456e-01</td>\n",
       "      <td>2.249113e-01</td>\n",
       "      <td>1.685709e-01</td>\n",
       "      <td>1.663145e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10216</th>\n",
       "      <td>0.211474</td>\n",
       "      <td>0.246075</td>\n",
       "      <td>0.126885</td>\n",
       "      <td>0.147645</td>\n",
       "      <td>1.229998e-01</td>\n",
       "      <td>1.435039e-01</td>\n",
       "      <td>6.833322e-02</td>\n",
       "      <td>7.972438e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10217</th>\n",
       "      <td>0.427104</td>\n",
       "      <td>0.433504</td>\n",
       "      <td>0.295183</td>\n",
       "      <td>0.299671</td>\n",
       "      <td>3.660964e-01</td>\n",
       "      <td>3.716535e-01</td>\n",
       "      <td>2.466318e-01</td>\n",
       "      <td>2.504399e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10218</th>\n",
       "      <td>0.322200</td>\n",
       "      <td>0.389644</td>\n",
       "      <td>0.200981</td>\n",
       "      <td>0.243292</td>\n",
       "      <td>2.591676e-01</td>\n",
       "      <td>3.145388e-01</td>\n",
       "      <td>1.524939e-01</td>\n",
       "      <td>1.853058e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10219</th>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.017873</td>\n",
       "      <td>0.009412</td>\n",
       "      <td>0.010724</td>\n",
       "      <td>1.000000e-16</td>\n",
       "      <td>1.000000e-16</td>\n",
       "      <td>1.000000e-16</td>\n",
       "      <td>1.000000e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10220</th>\n",
       "      <td>0.637677</td>\n",
       "      <td>0.618328</td>\n",
       "      <td>0.503037</td>\n",
       "      <td>0.487225</td>\n",
       "      <td>5.874342e-01</td>\n",
       "      <td>5.693322e-01</td>\n",
       "      <td>4.601651e-01</td>\n",
       "      <td>4.454377e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10221 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       chrf_b1_n16  chrf_b3_n16  chrf_b1_n110  chrf_b3_n110   chrf_b1_n26  \\\n",
       "0         0.169171     0.179917      0.101503      0.107950  1.118287e-01   \n",
       "1         0.134180     0.136271      0.080508      0.081762  7.799717e-02   \n",
       "2         0.370555     0.324404      0.222333      0.194642  3.144338e-01   \n",
       "3         0.237745     0.218189      0.142647      0.130914  1.717801e-01   \n",
       "4         0.254548     0.251340      0.190520      0.188031  2.278456e-01   \n",
       "...            ...          ...           ...           ...           ...   \n",
       "10216     0.211474     0.246075      0.126885      0.147645  1.229998e-01   \n",
       "10217     0.427104     0.433504      0.295183      0.299671  3.660964e-01   \n",
       "10218     0.322200     0.389644      0.200981      0.243292  2.591676e-01   \n",
       "10219     0.015686     0.017873      0.009412      0.010724  1.000000e-16   \n",
       "10220     0.637677     0.618328      0.503037      0.487225  5.874342e-01   \n",
       "\n",
       "        chrf_b3_n26  chrf_b1_n210  chrf_b3_n210  \n",
       "0      1.190255e-01  6.212704e-02  6.612526e-02  \n",
       "1      7.923357e-02  4.333176e-02  4.401865e-02  \n",
       "2      2.740581e-01  1.746855e-01  1.522545e-01  \n",
       "3      1.573495e-01  9.543338e-02  8.741637e-02  \n",
       "4      2.249113e-01  1.685709e-01  1.663145e-01  \n",
       "...             ...           ...           ...  \n",
       "10216  1.435039e-01  6.833322e-02  7.972438e-02  \n",
       "10217  3.716535e-01  2.466318e-01  2.504399e-01  \n",
       "10218  3.145388e-01  1.524939e-01  1.853058e-01  \n",
       "10219  1.000000e-16  1.000000e-16  1.000000e-16  \n",
       "10220  5.693322e-01  4.601651e-01  4.454377e-01  \n",
       "\n",
       "[10221 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I was surprised, but this works exactly like it's intended. Makes a new column with the chrF score for each row of the df.\n",
    "# The default n-gram values are min == 1, max == 6. \n",
    "# The default beta is 3.\n",
    "\n",
    "# Moreover, it is worthwhile to mention chrf uses its own tokenization with whitespaces.\n",
    "# All parameters to test chrf scores with. feel free to play around with this and test out different combinations.\n",
    "# Note: this takes a few minutes to run.\n",
    "min_len = [1,2]\n",
    "max_len = [6,10]\n",
    "beta = [1,3]\n",
    "\n",
    "for df in list(df_dict.values()):\n",
    "    chrf_scores=[]\n",
    "    for min_l in min_len:\n",
    "        for max_l in max_len:\n",
    "            for b in beta:\n",
    "                append_str = \"chrf_b\" + str(b) + \"_n\" + str(min_l) + str(max_l)\n",
    "                chrf_scores.append(append_str)\n",
    "                df[append_str] = df.apply(lambda row: chrf_score.sentence_chrf(row[\"reference\"],row[\"translation\"],min_len=min_l,max_len=max_l,beta=b),axis=1)\n",
    "                # Also add a z score column.\n",
    "                df[(append_str+ \"_zscore\")] = scaler.fit_transform(df[append_str].to_numpy().reshape(-1,1)).flatten()\n",
    "\n",
    "df_p.loc[:,chrf_scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ab6ed0",
   "metadata": {},
   "source": [
    "---\n",
    "### Comparison of Applied Metrics\n",
    "Because the numeric system used for all of these can be different, the best way to compare them is by checking the correlation with the annotator's scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bf7e3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dict to be transformed to a df later, for score comparison.\n",
    "corr_list = [\"pearson\",\"kendall\"]\n",
    "scores_dict = {}\n",
    "\n",
    "for df_name in df_dict.keys():\n",
    "    for corr in corr_list:\n",
    "        scores_dict[corr+\"_\"+df_name] = []\n",
    "    \n",
    "scores_index = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09bf78ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thankfully, Pandas has a corr method. Use it on standardized scores obtained previously.\n",
    "\n",
    "# for each declared corr method, compute the corr between each computed metric and the avg-score column for each considered df.\n",
    "for df_name in df_dict.keys():\n",
    "    for corr in corr_list:\n",
    "        for key in rouge_scores[0].keys():\n",
    "            scores_dict[corr+\"_\"+df_name].append(df_dict[df_name].loc[:,(key+ \"_zscore\")].corr(df_dict[df_name].loc[:,\"z-score\"],method=corr))\n",
    "        for chrf_score in set(chrf_scores):\n",
    "            scores_dict[corr+\"_\"+df_name].append(df_dict[df_name].loc[:,(chrf_score+\"_zscore\")].corr(df_dict[df_name].loc[:,\"z-score\"],method=corr))\n",
    "        for bleu_score in bleu_scores_list:\n",
    "            scores_dict[corr+\"_\"+df_name].append(df_dict[df_name].loc[:,(key+ \"_zscore\")].corr(df_dict[df_name].loc[:,\"z-score\"],method=corr))\n",
    "\n",
    "\n",
    "# Build also a list that will be used to create the index for the scores dataframe.\n",
    "scores_index.extend(list(rouge_scores[0].keys()))\n",
    "scores_index.extend(chrf_scores)\n",
    "scores_index.extend(bleu_scores_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "473f7b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pearson_df_u</th>\n",
       "      <th>kendall_df_u</th>\n",
       "      <th>pearson_df_p</th>\n",
       "      <th>kendall_df_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rouge-1</th>\n",
       "      <td>0.030981</td>\n",
       "      <td>0.017586</td>\n",
       "      <td>0.022735</td>\n",
       "      <td>-0.000530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge-2</th>\n",
       "      <td>0.020555</td>\n",
       "      <td>0.011268</td>\n",
       "      <td>0.014217</td>\n",
       "      <td>0.006591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge-l</th>\n",
       "      <td>0.031029</td>\n",
       "      <td>0.017586</td>\n",
       "      <td>0.022402</td>\n",
       "      <td>-0.000531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrf_b1_n16</th>\n",
       "      <td>0.402421</td>\n",
       "      <td>0.296409</td>\n",
       "      <td>0.401513</td>\n",
       "      <td>0.296313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrf_b3_n16</th>\n",
       "      <td>0.393190</td>\n",
       "      <td>0.303297</td>\n",
       "      <td>0.391742</td>\n",
       "      <td>0.303248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrf_b1_n110</th>\n",
       "      <td>0.392289</td>\n",
       "      <td>0.289472</td>\n",
       "      <td>0.391224</td>\n",
       "      <td>0.289480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrf_b3_n110</th>\n",
       "      <td>0.381700</td>\n",
       "      <td>0.293693</td>\n",
       "      <td>0.380012</td>\n",
       "      <td>0.293819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrf_b1_n26</th>\n",
       "      <td>0.417394</td>\n",
       "      <td>0.299659</td>\n",
       "      <td>0.416710</td>\n",
       "      <td>0.299855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrf_b3_n26</th>\n",
       "      <td>0.362991</td>\n",
       "      <td>0.289820</td>\n",
       "      <td>0.361257</td>\n",
       "      <td>0.289655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrf_b1_n210</th>\n",
       "      <td>0.432033</td>\n",
       "      <td>0.310521</td>\n",
       "      <td>0.431516</td>\n",
       "      <td>0.310629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrf_b3_n210</th>\n",
       "      <td>0.355049</td>\n",
       "      <td>0.283801</td>\n",
       "      <td>0.353059</td>\n",
       "      <td>0.283748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basic bleu</th>\n",
       "      <td>0.031029</td>\n",
       "      <td>0.017586</td>\n",
       "      <td>0.022402</td>\n",
       "      <td>-0.000531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pearson_df_u  kendall_df_u  pearson_df_p  kendall_df_p\n",
       "rouge-1           0.030981      0.017586      0.022735     -0.000530\n",
       "rouge-2           0.020555      0.011268      0.014217      0.006591\n",
       "rouge-l           0.031029      0.017586      0.022402     -0.000531\n",
       "chrf_b1_n16       0.402421      0.296409      0.401513      0.296313\n",
       "chrf_b3_n16       0.393190      0.303297      0.391742      0.303248\n",
       "chrf_b1_n110      0.392289      0.289472      0.391224      0.289480\n",
       "chrf_b3_n110      0.381700      0.293693      0.380012      0.293819\n",
       "chrf_b1_n26       0.417394      0.299659      0.416710      0.299855\n",
       "chrf_b3_n26       0.362991      0.289820      0.361257      0.289655\n",
       "chrf_b1_n210      0.432033      0.310521      0.431516      0.310629\n",
       "chrf_b3_n210      0.355049      0.283801      0.353059      0.283748\n",
       "basic bleu        0.031029      0.017586      0.022402     -0.000531"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(scores_dict,index=scores_index)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7942b860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max in pearson_df_u:\n",
      "9, with 0.4320332033424246\n",
      "Max in kendall_df_u:\n",
      "9, with 0.310521144780342\n",
      "Max in pearson_df_p:\n",
      "9, with 0.4315164961782167\n",
      "Max in kendall_df_p:\n",
      "9, with 0.31062865883067975\n"
     ]
    }
   ],
   "source": [
    "for column in scores_df.columns:\n",
    "    print(f\"Max in {column}:\")\n",
    "    print(\"{}, with {}\".format(scores_df[column].argmax(),scores_df[column].max()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f41744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
