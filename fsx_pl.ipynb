{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from typing import List, Union, Dict\n",
    "import torch\n",
    "from torch import nn, tensor\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "import re\n",
    "\n",
    "# pytorch related imports\n",
    "import torch\n",
    "from torch.nn import *\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# lightning related imports\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "# metrics\n",
    "from torchmetrics.functional import mean_absolute_error, mean_squared_error\n",
    "from metrics.regression_metrics import t_kendalltau, t_pearson, t_spearman\n",
    "\n",
    "# sklearn related imports\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "from fnet import *\n",
    "\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "srt = [\"source\", \"reference\", \"translation\"]\n",
    "language_pairs = [\n",
    "    \"cs-en\",\n",
    "    \"de-en\",\n",
    "    \"en-fi\",\n",
    "    \"en-zh\",\n",
    "    \"ru-en\",\n",
    "    \"zh-en\",\n",
    "]\n",
    "scores = {pair: pd.read_csv(f\"corpus/{pair}/scores.csv\") for pair in language_pairs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = \"de-en\"\n",
    "embedding_ref = torch.from_numpy(np.load(f\"corpus/{pair}/laser.reference_embeds.npy\")).float()\n",
    "embedding_src = torch.from_numpy(np.load(f\"corpus/{pair}/laser.source_embeds.npy\")).float()\n",
    "embedding_hyp = torch.from_numpy(np.load(f\"corpus/{pair}/laser.translation_embeds.npy\")).float()\n",
    "score = tensor(scores[pair][\"z-score\"]).unsqueeze(1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21704, 1024])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21704, 1, 32, 32])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_ref = torch.reshape(embedding_ref, (embedding_ref.shape[0], 32, 32)).unsqueeze(1)\n",
    "img_src = torch.reshape(embedding_src, (embedding_ref.shape[0], 32, 32)).unsqueeze(1)\n",
    "img_hyp = torch.reshape(embedding_hyp, (embedding_ref.shape[0], 32, 32)).unsqueeze(1)\n",
    "img_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21704, 3, 32, 32])\n",
      "torch.Size([21704, 1])\n"
     ]
    }
   ],
   "source": [
    "imgs = torch.cat([img_src, img_ref, img_hyp], dim=1)\n",
    "print(imgs.shape)\n",
    "print(score.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SHAPE1 = 1024\n",
    "EMBEDDING_SHAPE2 = 1\n",
    "\n",
    "\n",
    "class TextMiningDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self, batch_size, pair, dims,\n",
    "    ):\n",
    "        super().__init__(dims=dims,)\n",
    "        self.batch_size = batch_size\n",
    "        self.pair = pair\n",
    "\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            embedding_ref = torch.from_numpy(\n",
    "                np.load(f\"corpus/{self.pair}/laser.reference_embeds.npy\")\n",
    "            ).float()\n",
    "            embedding_src = torch.from_numpy(\n",
    "                np.load(f\"corpus/{self.pair}/laser.source_embeds.npy\")\n",
    "            ).float()\n",
    "            embedding_hyp = torch.from_numpy(\n",
    "                np.load(f\"corpus/{self.pair}/laser.translation_embeds.npy\")\n",
    "            ).float()\n",
    "            train_size = embedding_ref.shape[0]\n",
    "            train_img_ref = torch.reshape(\n",
    "                embedding_ref, (train_size, EMBEDDING_SHAPE1, EMBEDDING_SHAPE2)\n",
    "            ).unsqueeze(1)\n",
    "            train_img_src = torch.reshape(\n",
    "                embedding_src, (train_size, EMBEDDING_SHAPE1, EMBEDDING_SHAPE2)\n",
    "            ).unsqueeze(1)\n",
    "            train_img_hyp = torch.reshape(\n",
    "                embedding_hyp, (train_size, EMBEDDING_SHAPE1, EMBEDDING_SHAPE2)\n",
    "            ).unsqueeze(1)\n",
    "            train_imgs = torch.cat([train_img_src, train_img_ref, train_img_hyp], dim=1)\n",
    "            # train_imgs = torch.cat([train_img_ref, train_img_hyp], dim=1)\n",
    "\n",
    "            train_target = tensor(scores[self.pair][\"z-score\"]).unsqueeze(1).float()\n",
    "\n",
    "            ds_full = TensorDataset(train_imgs, train_target)\n",
    "            self.ds_train, self.ds_val = random_split(\n",
    "                ds_full,\n",
    "                [int(train_size * (0.9)), int(train_size - int(train_size * (0.9)))],\n",
    "            )\n",
    "        if stage == \"test\" or stage is None:\n",
    "            embedding_ref = torch.from_numpy(\n",
    "                np.load(f\"testset/{self.pair}/laser.reference_embeds.npy\")\n",
    "            ).float()\n",
    "            embedding_src = torch.from_numpy(\n",
    "                np.load(f\"testset/{self.pair}/laser.source_embeds.npy\")\n",
    "            ).float()\n",
    "            embedding_hyp = torch.from_numpy(\n",
    "                np.load(f\"testset/{self.pair}/laser.translation_embeds.npy\")\n",
    "            ).float()\n",
    "            test_size = embedding_ref.shape[0]\n",
    "            test_img_ref = torch.reshape(\n",
    "                embedding_ref, (test_size, EMBEDDING_SHAPE1, EMBEDDING_SHAPE2)\n",
    "            ).unsqueeze(1)\n",
    "            test_img_src = torch.reshape(\n",
    "                embedding_src, (test_size, EMBEDDING_SHAPE1, EMBEDDING_SHAPE2)\n",
    "            ).unsqueeze(1)\n",
    "            test_img_hyp = torch.reshape(\n",
    "                embedding_hyp, (test_size, EMBEDDING_SHAPE1, EMBEDDING_SHAPE2)\n",
    "            ).unsqueeze(1)\n",
    "            test_imgs = torch.cat([test_img_src, test_img_ref, test_img_hyp], dim=1)\n",
    "            # test_imgs = torch.cat([test_img_ref, test_img_hyp], dim=1)\n",
    "            self.ds_test = TensorDataset(test_imgs, torch.zeros((test_size, 1)))\n",
    "\n",
    "    def train_dataloader(\n",
    "        self,\n",
    "    ) -> Union[DataLoader, List[DataLoader], Dict[str, DataLoader]]:\n",
    "        return DataLoader(\n",
    "            self.ds_train, batch_size=self.batch_size, shuffle=True, num_workers=12\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> Union[DataLoader, List[DataLoader]]:\n",
    "        return DataLoader(self.ds_val, batch_size=self.batch_size, num_workers=12)\n",
    "\n",
    "    def test_dataloader(self) -> Union[DataLoader, List[DataLoader]]:\n",
    "        return DataLoader(self.ds_test, batch_size=self.batch_size, num_workers=12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(monitor='val_loss', patience=5, verbose=False, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationPredictionLogger(Callback):\n",
    "    def __init__(self, val_samples, num_samples=32):\n",
    "        super().__init__()\n",
    "        self.num_samples = num_samples\n",
    "        self.val_imgs, self.val_score = val_samples\n",
    "\n",
    "    def on_validation_batch_end(\n",
    "        self, trainer, pl_module,\n",
    "    ):\n",
    "        val_imgs = self.val_imgs.to(device=pl_module.device)\n",
    "        val_score = self.val_score.to(device=pl_module.device)\n",
    "\n",
    "        predictions = pl_module(val_imgs)\n",
    "        trainer.logger.experiment.log(\n",
    "            {\n",
    "                \"examples\": [\n",
    "                    wandb.Image(x, caption=f\"Prediction:{p}, Score: {y}\")\n",
    "                    for x, p, y in zip(\n",
    "                        val_imgs[: self.num_samples],\n",
    "                        predictions[: self.num_samples],\n",
    "                        val_score[: self.num_samples],\n",
    "                    )\n",
    "                ]\n",
    "            }\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_1 = 64\n",
    "FEATURES_2 = FEATURES_1 * 2\n",
    "FEATURES_3 = FEATURES_2 * 2\n",
    "FEATURES_4 = FEATURES_3 * 2\n",
    "FEATURES_5 = FEATURES_4 * 2\n",
    "\n",
    "class Model(pl.LightningModule):\n",
    "    def __init__(self, input_shape, learning_rate=0.001):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.c1 = Conv2d(3, FEATURES_1, (3, 1), 1, (1, 0))\n",
    "        self.c2 = Conv2d(FEATURES_1, FEATURES_1, (3, 1), 1, (1, 0)) # 32\n",
    "        self.c3 = Conv2d(FEATURES_1, FEATURES_2, (3, 1), 4, (1, 0)) # 24\n",
    "        self.c4 = Conv2d(FEATURES_2, FEATURES_3, (3, 1), 2, (1, 0)) # 16\n",
    "        self.c5 = Conv2d(FEATURES_3, FEATURES_4, (3, 1), 2, (1, 0)) # 8\n",
    "        self.c6 = Conv2d(FEATURES_4, FEATURES_5, (3, 1), 2, (1, 0)) # 2\n",
    "        self.bn = BatchNorm2d(FEATURES_1)\n",
    "        self.bn3 = BatchNorm2d(FEATURES_2)\n",
    "        self.bn4 = BatchNorm2d(FEATURES_3)\n",
    "        self.bn5 = BatchNorm2d(FEATURES_4)\n",
    "        self.bn6 = BatchNorm2d(FEATURES_5)\n",
    "        self.fc1 = Linear(32 * FEATURES_5, 256)\n",
    "        self.fc2 = Linear(256, 64)\n",
    "        self.fc3 = Linear(64, 1)\n",
    "\n",
    "    def _forward_features(self, x):\n",
    "        x = self.bn(F.relu(self.c1(x)))\n",
    "        # x = self.bn(F.relu(self.c2(x) + x))\n",
    "        # x = self.bn(F.relu(self.c2(x) + x))\n",
    "        # x = self.bn(F.relu(self.c2(x) + x))\n",
    "        x = self.bn(F.relu(self.c2(x)))\n",
    "        x = self.bn3(F.relu(self.c3(x)))\n",
    "        x = self.bn4(F.relu(self.c4(x)))\n",
    "        x = self.bn5(F.relu(self.c5(x)))\n",
    "        # x = self.bn6(F.relu(self.c6(x)))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        # print(x.shape)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.mse_loss(logits, y)\n",
    "        mse = mean_squared_error(logits, y)\n",
    "        mae = mean_absolute_error(logits, y)\n",
    "        k = t_kendalltau(logits, y)\n",
    "        p = t_pearson(logits, y)\n",
    "        s = t_spearman(logits, y)\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log(\"train_mse\", mse, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log(\"train_mae\", mae, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log(\"train_kendalltau\", k, on_step=False, on_epoch=True, logger=True)\n",
    "        self.log(\"train_pearson\", p, on_step=False, on_epoch=True, logger=True)\n",
    "        self.log(\"train_spearman\", s, on_step=False, on_epoch=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.mse_loss(logits, y)\n",
    "        mse = mean_squared_error(logits, y)\n",
    "        mae = mean_absolute_error(logits, y)\n",
    "        k = t_kendalltau(logits, y)\n",
    "        p = t_pearson(logits, y)\n",
    "        s = t_spearman(logits, y)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_mse\", mse, prog_bar=True)\n",
    "        self.log(\"val_mae\", mae, prog_bar=True)\n",
    "        self.log(\"val_kendalltau\", k, on_step=False, prog_bar=True)\n",
    "        self.log(\"val_pearson\", p, on_step=False, prog_bar=True)\n",
    "        self.log(\"val_spearman\", s, on_step=False, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.mse_loss(logits, y)\n",
    "        mse = mean_squared_error(logits, y)\n",
    "        mae = mean_absolute_error(logits, y)\n",
    "        k = t_kendalltau(logits, y)\n",
    "        p = t_pearson(logits, y)\n",
    "        s = t_spearman(logits, y)\n",
    "        self.log(\"test_loss\", loss, on_step=True, prog_bar=True)\n",
    "        self.log(\"test_mse\", mse, on_step=True, prog_bar=True)\n",
    "        self.log(\"test_mae\", mae, on_step=True, prog_bar=True)\n",
    "        self.log(\"test_kendalltau\", k, prog_bar=True)\n",
    "        self.log(\"test_pearson\", p, prog_bar=True)\n",
    "        self.log(\"test_spearman\", s, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FourierTransformerDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_transform2d(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Applies 2d fourier transform\n",
    "\n",
    "    Args:\n",
    "        x (torch.Tensor):\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: \n",
    "    \"\"\"\n",
    "    return torch.fft.fft2(x, dim=(-1, -2)).real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(Module):\n",
    "    def __init__(self, d_model: int, dim_ff:int=2048, dropout:float = 0.1):\n",
    "        super().__init__()\n",
    "        self.ff = Sequential(\n",
    "            Linear(d_model, dim_ff),\n",
    "            GELU(),\n",
    "            Dropout(dropout),\n",
    "            Linear(dim_ff, d_model)\n",
    "            Dropout(dropout)\n",
    "        )\n",
    "        self.norm1 = LayerNorm(d_model)\n",
    "        self.dropout1 = Dropout(dropout)\n",
    "        self.norm2 = LayerNorm(d_model)\n",
    "        self.dropout2 = Dropout(dropout)\n",
    "        self.norm3 = LayerNorm(d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        i = x\n",
    "        x += self.dropout1(fourier_transform2d(x))\n",
    "        x = self.norm1(x)\n",
    "        x += self.dropout2(i)\n",
    "        x = self.norm2(x)\n",
    "        x += self.ff(x)\n",
    "        x = self.norm3(x)\n",
    "        return x\n",
    "\n",
    "class FNet(TransformerDecoder):\n",
    "    def __init__(self, num_layers, d_model: int,dim_ff:int=2048, dropout:float = 0.1):\n",
    "        decoder_layer = DecoderLayer(d_model, dim_ff, dropout)\n",
    "        super().__init__(decoder_layer, num_layers)\n",
    "        self.num_layers = num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_1 = 64\n",
    "FEATURES_2 = FEATURES_1 * 2\n",
    "FEATURES_3 = FEATURES_2 * 2\n",
    "FEATURES_4 = FEATURES_3 * 2\n",
    "FEATURES_5 = FEATURES_4 * 2\n",
    "\n",
    "class Decoder(TransformerDecoder):\n",
    "    def __init__(self, decoder_layer, num_layers, norm):\n",
    "        super().__init__(decoder_layer, num_layers, norm=norm)\n",
    "\n",
    "class Model(pl.LightningModule):\n",
    "    def __init__(self, input_shape, learning_rate=0.001):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.c1 = Conv2d(3, FEATURES_1, (3, 1), 1, (1, 0))\n",
    "        self.c2 = Conv2d(FEATURES_1, FEATURES_1, (3, 1), 1, (1, 0)) # 32\n",
    "        self.c3 = Conv2d(FEATURES_1, FEATURES_2, (3, 1), 4, (1, 0)) # 24\n",
    "        self.c4 = Conv2d(FEATURES_2, FEATURES_3, (3, 1), 2, (1, 0)) # 16\n",
    "        self.c5 = Conv2d(FEATURES_3, FEATURES_4, (3, 1), 2, (1, 0)) # 8\n",
    "        self.c6 = Conv2d(FEATURES_4, FEATURES_5, (3, 1), 2, (1, 0)) # 2\n",
    "        self.bn = BatchNorm2d(FEATURES_1)\n",
    "        self.bn3 = BatchNorm2d(FEATURES_2)\n",
    "        self.bn4 = BatchNorm2d(FEATURES_3)\n",
    "        self.bn5 = BatchNorm2d(FEATURES_4)\n",
    "        self.bn6 = BatchNorm2d(FEATURES_5)\n",
    "        self.fc1 = Linear(32 * FEATURES_5, 1)\n",
    "        self.fc3 = Linear(64, 1)\n",
    "\n",
    "    def _forward_features(self, x):\n",
    "        x = self.bn(F.relu(self.c1(x)))\n",
    "        # x = self.bn(F.relu(self.c2(x) + x))\n",
    "        # x = self.bn(F.relu(self.c2(x) + x))\n",
    "        # x = self.bn(F.relu(self.c2(x) + x))\n",
    "        x = self.bn(F.relu(self.c2(x)))\n",
    "        x = self.bn3(F.relu(self.c3(x)))\n",
    "        x = self.bn4(F.relu(self.c4(x)))\n",
    "        x = self.bn5(F.relu(self.c5(x)))\n",
    "        # x = self.bn6(F.relu(self.c6(x)))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        # print(x.shape)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.mse_loss(logits, y)\n",
    "        mse = mean_squared_error(logits, y)\n",
    "        mae = mean_absolute_error(logits, y)\n",
    "        k = t_kendalltau(logits, y)\n",
    "        p = t_pearson(logits, y)\n",
    "        s = t_spearman(logits, y)\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log(\"train_mse\", mse, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log(\"train_mae\", mae, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log(\"train_kendalltau\", k, on_step=False, on_epoch=True, logger=True)\n",
    "        self.log(\"train_pearson\", p, on_step=False, on_epoch=True, logger=True)\n",
    "        self.log(\"train_spearman\", s, on_step=False, on_epoch=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.mse_loss(logits, y)\n",
    "        mse = mean_squared_error(logits, y)\n",
    "        mae = mean_absolute_error(logits, y)\n",
    "        k = t_kendalltau(logits, y)\n",
    "        p = t_pearson(logits, y)\n",
    "        s = t_spearman(logits, y)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_mse\", mse, prog_bar=True)\n",
    "        self.log(\"val_mae\", mae, prog_bar=True)\n",
    "        self.log(\"val_kendalltau\", k, on_step=False, prog_bar=True)\n",
    "        self.log(\"val_pearson\", p, on_step=False, prog_bar=True)\n",
    "        self.log(\"val_spearman\", s, on_step=False, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.mse_loss(logits, y)\n",
    "        mse = mean_squared_error(logits, y)\n",
    "        mae = mean_absolute_error(logits, y)\n",
    "        k = t_kendalltau(logits, y)\n",
    "        p = t_pearson(logits, y)\n",
    "        s = t_spearman(logits, y)\n",
    "        self.log(\"test_loss\", loss, on_step=True, prog_bar=True)\n",
    "        self.log(\"test_mse\", mse, on_step=True, prog_bar=True)\n",
    "        self.log(\"test_mae\", mae, on_step=True, prog_bar=True)\n",
    "        self.log(\"test_kendalltau\", k, prog_bar=True)\n",
    "        self.log(\"test_pearson\", p, prog_bar=True)\n",
    "        self.log(\"test_spearman\", s, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training + Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = TextMiningDataModule(256, \"de-en\", (3,32,32))\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_samples = next(iter(dm.train_dataloader()))\n",
    "# val_imgs, val_score = val_samples\n",
    "# val_imgs.shape, val_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "model = Model(dm.dims, learning_rate=0.0001)\n",
    "# wandb_logger = WandbLogger(project=\"wandb-lightning\", job_type=\"train\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=30,\n",
    "    progress_bar_refresh_rate=1,\n",
    "    gpus=1,\n",
    "    # logger=wandb_logger,\n",
    "    # callbacks=[early_stop_callback],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name | Type        | Params\n",
      "--------------------------------------\n",
      "0  | c1   | Conv2d      | 640   \n",
      "1  | c2   | Conv2d      | 12.4 K\n",
      "2  | c3   | Conv2d      | 24.7 K\n",
      "3  | c4   | Conv2d      | 98.6 K\n",
      "4  | c5   | Conv2d      | 393 K \n",
      "5  | c6   | Conv2d      | 1.6 M \n",
      "6  | bn   | BatchNorm2d | 128   \n",
      "7  | bn3  | BatchNorm2d | 256   \n",
      "8  | bn4  | BatchNorm2d | 512   \n",
      "9  | bn5  | BatchNorm2d | 1.0 K \n",
      "10 | bn6  | BatchNorm2d | 2.0 K \n",
      "11 | fc1  | Linear      | 8.4 M \n",
      "12 | fc2  | Linear      | 16.4 K\n",
      "13 | fc3  | Linear      | 65    \n",
      "--------------------------------------\n",
      "10.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.5 M    Total params\n",
      "42.053    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 86/86 [00:07<00:00, 12.15it/s, loss=0.106, v_num=42, val_loss=1.690, val_mse=1.690, val_mae=1.140, val_kendalltau=0.0253, val_pearson=0.0248, val_spearman=0.0368]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{'val_kendalltau': 0.041737161576747894,\n",
      " 'val_loss': 1.622091293334961,\n",
      " 'val_mae': 1.1172127723693848,\n",
      " 'val_mse': 1.622091293334961,\n",
      " 'val_pearson': 0.09263288229703903,\n",
      " 'val_spearman': 0.06260263919830322}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 1.622091293334961,\n",
       "  'val_mse': 1.622091293334961,\n",
       "  'val_mae': 1.1172127723693848,\n",
       "  'val_kendalltau': 0.041737161576747894,\n",
       "  'val_pearson': 0.09263288229703903,\n",
       "  'val_spearman': 0.06260263919830322}]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f8b00cba333cbc52f2b9024e2fd0f03f267bd4c88e752638d58a81ffee90e795"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('pl': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}