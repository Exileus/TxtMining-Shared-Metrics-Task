{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "dense_network.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NwOJarh2tzp",
        "outputId": "8d2fa19a-a9e4-4183-e607-77e0ce15afc4"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install gdown # download from google drive"
      ],
      "id": "0NwOJarh2tzp",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR0VPq1xBKgM"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "\n",
        "import torch\n",
        "import pickle\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "\n",
        "from transformers import BertModel, BertTokenizerFast"
      ],
      "id": "dR0VPq1xBKgM",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whole-deficit"
      },
      "source": [
        "# Language-agnostic BERT Sentence Embedding (LaBSE)\n",
        "\n",
        "LaBSE is a recent transformer model developed by google to create Language Agnostic Embeddings.\n",
        "\n",
        "According to their results LaBSE outperforms LASER in most multilingual benchmarks with the advantage of running well in windows 😂.\n",
        "\n",
        "In this notebook I will give you the basics on \"how to get sentence embeddings using LaBSE\". I hope that this will foster some ideas for the project.\n",
        "\n",
        "[Official Google blog](https://ai.googleblog.com/2020/08/language-agnostic-bert-sentence.html)"
      ],
      "id": "whole-deficit"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IGm5Eis106i"
      },
      "source": [
        "LaBSE follows a dual encoder architecture in which the source (text to be translated) and target text (translated text) are encoded using a shared transformer embedding network separately. The model is then trained in a translation ranking task in which the text representations of paraphares and translations is forced to be close together."
      ],
      "id": "3IGm5Eis106i"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxZ9f1Fh2aRi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e68f2629-df9f-4820-fc5d-e18493670565"
      },
      "source": [
        "# Transformer loading and initialization\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"setu4993/LaBSE\")\n",
        "labse = BertModel.from_pretrained(\"setu4993/LaBSE\")\n",
        "if torch.cuda.is_available():\n",
        "    labse = labse.cuda()\n",
        "    print('cuda available')\n",
        "labse = labse.eval()"
      ],
      "id": "uxZ9f1Fh2aRi",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vs8y1NbH3f1T"
      },
      "source": [
        "# DATASET"
      ],
      "id": "Vs8y1NbH3f1T"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FseKAayT-XRz",
        "outputId": "1e51de5f-2698-43c4-84af-c2cf8e850a2e"
      },
      "source": [
        "%cd /content/\n",
        "%rm -rf /content/corpus/\n",
        "\n",
        "!gdown https://drive.google.com/uc?id=1AB2pkEQ0muhhUC7hq2dyjewRCdluX4RK\n",
        "!unzip corpus.zip\n",
        "%rm -rf corpus.zip"
      ],
      "id": "FseKAayT-XRz",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1AB2pkEQ0muhhUC7hq2dyjewRCdluX4RK\n",
            "To: /content/corpus.zip\n",
            "17.8MB [00:00, 31.5MB/s]\n",
            "Archive:  corpus.zip\n",
            "   creating: corpus/.ipynb_checkpoints/\n",
            "  inflating: corpus/.ipynb_checkpoints/preprocessing-checkpoint.ipynb  \n",
            "   creating: corpus/cs-en/\n",
            "  inflating: corpus/cs-en/scores.csv  \n",
            "   creating: corpus/de-en/\n",
            "   creating: corpus/de-en/.ipynb_checkpoints/\n",
            "  inflating: corpus/de-en/.ipynb_checkpoints/BLEUscore-checkpoint.ipynb  \n",
            "  inflating: corpus/de-en/.ipynb_checkpoints/ROUGE-checkpoint.ipynb  \n",
            "  inflating: corpus/de-en/BLEUscore.ipynb  \n",
            "  inflating: corpus/de-en/chrF_img.png  \n",
            "  inflating: corpus/de-en/laser.ipynb  \n",
            "  inflating: corpus/de-en/ROUGE.ipynb  \n",
            "  inflating: corpus/de-en/scores.csv  \n",
            "   creating: corpus/en-fi/\n",
            "  inflating: corpus/en-fi/.DS_Store  \n",
            "  inflating: corpus/en-fi/relative-ranks.csv  \n",
            "  inflating: corpus/en-fi/scores.csv  \n",
            "   creating: corpus/en-zh/\n",
            "  inflating: corpus/en-zh/scores.csv  \n",
            "   creating: corpus/ru-en/\n",
            "  inflating: corpus/ru-en/scores.csv  \n",
            "   creating: corpus/zh-en/\n",
            "  inflating: corpus/zh-en/scores.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "Xh9E5hXO30ee",
        "outputId": "b6b0ebac-5f8a-4bee-e7bf-0da498cec256"
      },
      "source": [
        "scores_en_zh = pd.read_csv(\"corpus/en-zh/scores.csv\")\n",
        "scores_en_zh.head(2)"
      ],
      "id": "Xh9E5hXO30ee",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>reference</th>\n",
              "      <th>translation</th>\n",
              "      <th>z-score</th>\n",
              "      <th>avg-score</th>\n",
              "      <th>annotators</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"In the GISS model's simulation, Venus' slow s...</td>\n",
              "      <td>GSIS的科学家AnthonyDelGenio在新闻稿中解释说：“在GISS模型的模拟模型中...</td>\n",
              "      <td>戈达德太空研究所科学家安东尼·德尔·杰尼奥在新闻发布会上解释说：“在戈达德太空研究所的模型模...</td>\n",
              "      <td>-1.171867</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ai Yanhan of China in the Women's 4 x 200m Fre...</td>\n",
              "      <td>中国在英国女性4x200mFreestreyWTE中的最后被称为：“中国14岁的孩子从球下降...</td>\n",
              "      <td>参加女子4x200米自由泳接力赛决赛的中国小将艾衍含被这样描述：“那名14岁的中国小姑娘犯了...</td>\n",
              "      <td>-2.255403</td>\n",
              "      <td>26.5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              source  ... annotators\n",
              "0  \"In the GISS model's simulation, Venus' slow s...  ...          1\n",
              "1  Ai Yanhan of China in the Women's 4 x 200m Fre...  ...          2\n",
              "\n",
              "[2 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSlPrNvy4CFw"
      },
      "source": [
        "srt = [\"source\", \"reference\", \"translation\"]\n",
        "language_pairs = [\n",
        "    \"cs-en\",\n",
        "    \"de-en\",\n",
        "    \"en-fi\",\n",
        "    \"en-zh\",\n",
        "    \"ru-en\",\n",
        "    \"zh-en\",\n",
        "]\n",
        "scores = {pair: pd.read_csv(f\"corpus/{pair}/scores.csv\") for pair in language_pairs}"
      ],
      "id": "jSlPrNvy4CFw",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOW_3Ty19tfG",
        "outputId": "15a72cf9-0a86-47ec-d636-286abc486179"
      },
      "source": [
        "scores['cs-en']['avg-score'].head(2).tolist()"
      ],
      "id": "IOW_3Ty19tfG",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[60.0, 44.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw08XQ2M7Xtw"
      },
      "source": [
        "#Calculate LaBSE tokens\n",
        "\n",
        "tokens = {pair: {t: tokenizer(scores[pair][t].tolist(),\n",
        "                              return_tensors=\"pt\", # pytorch\n",
        "                              padding=True # padding to the longest in a batch\n",
        "                              ) for t in srt} for pair in language_pairs}"
      ],
      "id": "rw08XQ2M7Xtw",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylev6xxqK7TY"
      },
      "source": [
        "#tokens[\"cs-en\"]['source'].keys()"
      ],
      "id": "ylev6xxqK7TY",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTYMr06aDkWA"
      },
      "source": [
        "def calcEmbeddings(tokens, N_patittions=200):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        input_ids = torch.chunk(tokens['input_ids'].cuda(), N_patittions)\n",
        "        token_type_ids = torch.chunk(tokens['token_type_ids'].cuda(), N_patittions)\n",
        "        attention_mask = torch.chunk(tokens['attention_mask'].cuda(), N_patittions)\n",
        "    else:\n",
        "        input_ids = torch.chunk(tokens['input_ids'], N_patittions)\n",
        "        token_type_ids = torch.chunk(tokens['token_type_ids'], N_patittions)\n",
        "        attention_mask = torch.chunk(tokens['attention_mask'], N_patittions)\n",
        "    N_patittions = len(input_ids)\n",
        "\n",
        "    # initialization\n",
        "    token = {'input_ids' : input_ids[0],\n",
        "            'token_type_ids': token_type_ids[0],\n",
        "            'attention_mask' : attention_mask[0]\n",
        "            }\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        embeddings = labse(**token).pooler_output\n",
        "\n",
        "    for p in tqdm(range(1, N_patittions)):\n",
        "        token = {'input_ids' : input_ids[p],\n",
        "                 'token_type_ids': token_type_ids[p],\n",
        "                 'attention_mask' : attention_mask[p]\n",
        "                 }\n",
        "        with torch.no_grad():\n",
        "            embeddings = torch.cat([embeddings, labse(**token).pooler_output])\n",
        "    \n",
        "    return embeddings"
      ],
      "id": "dTYMr06aDkWA",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvDxdvLcBgz-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7ce3780-279e-41bb-b285-fa99d5db22a9"
      },
      "source": [
        "# calculate embeddings\n",
        "\n",
        "embeddings = {pair: {t: calcEmbeddings(tokens[pair][t]) for t in srt}\n",
        "                    for pair in language_pairs}"
      ],
      "id": "TvDxdvLcBgz-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/199 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|▏         | 3/199 [00:00<00:27,  7.11it/s]\u001b[A\n",
            "  2%|▏         | 4/199 [00:00<00:38,  5.11it/s]\u001b[A\n",
            "  3%|▎         | 5/199 [00:01<00:46,  4.19it/s]\u001b[A\n",
            "  3%|▎         | 6/199 [00:01<00:52,  3.68it/s]\u001b[A\n",
            "  4%|▎         | 7/199 [00:01<00:55,  3.47it/s]\u001b[A\n",
            "  4%|▍         | 8/199 [00:02<00:58,  3.29it/s]\u001b[A\n",
            "  5%|▍         | 9/199 [00:02<01:00,  3.16it/s]\u001b[A\n",
            "  5%|▌         | 10/199 [00:02<01:00,  3.12it/s]\u001b[A\n",
            "  6%|▌         | 11/199 [00:03<01:01,  3.06it/s]\u001b[A\n",
            "  6%|▌         | 12/199 [00:03<01:02,  3.01it/s]\u001b[A\n",
            "  7%|▋         | 13/199 [00:03<01:01,  3.01it/s]\u001b[A\n",
            "  7%|▋         | 14/199 [00:04<01:02,  2.98it/s]\u001b[A\n",
            "  8%|▊         | 15/199 [00:04<01:02,  2.95it/s]\u001b[A\n",
            "  8%|▊         | 16/199 [00:04<01:01,  2.96it/s]\u001b[A\n",
            "  9%|▊         | 17/199 [00:05<01:01,  2.94it/s]\u001b[A\n",
            "  9%|▉         | 18/199 [00:05<01:01,  2.93it/s]\u001b[A\n",
            " 10%|▉         | 19/199 [00:05<01:01,  2.95it/s]\u001b[A\n",
            " 10%|█         | 20/199 [00:06<01:01,  2.93it/s]\u001b[A\n",
            " 11%|█         | 21/199 [00:06<01:01,  2.92it/s]\u001b[A\n",
            " 11%|█         | 22/199 [00:06<01:00,  2.92it/s]\u001b[A\n",
            " 12%|█▏        | 23/199 [00:07<01:00,  2.91it/s]\u001b[A\n",
            " 12%|█▏        | 24/199 [00:07<01:00,  2.91it/s]\u001b[A\n",
            " 13%|█▎        | 25/199 [00:07<00:59,  2.92it/s]\u001b[A\n",
            " 13%|█▎        | 26/199 [00:08<00:59,  2.91it/s]\u001b[A\n",
            " 14%|█▎        | 27/199 [00:08<00:59,  2.91it/s]\u001b[A\n",
            " 14%|█▍        | 28/199 [00:08<00:58,  2.91it/s]\u001b[A\n",
            " 15%|█▍        | 29/199 [00:09<00:58,  2.89it/s]\u001b[A\n",
            " 15%|█▌        | 30/199 [00:09<00:58,  2.90it/s]\u001b[A\n",
            " 16%|█▌        | 31/199 [00:09<00:58,  2.89it/s]\u001b[A\n",
            " 16%|█▌        | 32/199 [00:10<00:57,  2.89it/s]\u001b[A\n",
            " 17%|█▋        | 33/199 [00:10<00:57,  2.89it/s]\u001b[A\n",
            " 17%|█▋        | 34/199 [00:11<00:57,  2.89it/s]\u001b[A\n",
            " 18%|█▊        | 35/199 [00:11<00:56,  2.88it/s]\u001b[A\n",
            " 18%|█▊        | 36/199 [00:11<00:56,  2.89it/s]\u001b[A\n",
            " 19%|█▊        | 37/199 [00:12<00:56,  2.89it/s]\u001b[A\n",
            " 19%|█▉        | 38/199 [00:12<00:55,  2.88it/s]\u001b[A\n",
            " 20%|█▉        | 39/199 [00:12<00:55,  2.88it/s]\u001b[A\n",
            " 20%|██        | 40/199 [00:13<00:55,  2.88it/s]\u001b[A\n",
            " 21%|██        | 41/199 [00:13<00:55,  2.87it/s]\u001b[A\n",
            " 21%|██        | 42/199 [00:13<00:54,  2.87it/s]\u001b[A\n",
            " 22%|██▏       | 43/199 [00:14<00:54,  2.86it/s]\u001b[A\n",
            " 22%|██▏       | 44/199 [00:14<00:54,  2.86it/s]\u001b[A\n",
            " 23%|██▎       | 45/199 [00:14<00:53,  2.86it/s]\u001b[A\n",
            " 23%|██▎       | 46/199 [00:15<00:53,  2.86it/s]\u001b[A\n",
            " 24%|██▎       | 47/199 [00:15<00:53,  2.85it/s]\u001b[A\n",
            " 24%|██▍       | 48/199 [00:15<00:52,  2.85it/s]\u001b[A\n",
            " 25%|██▍       | 49/199 [00:16<00:52,  2.85it/s]\u001b[A\n",
            " 25%|██▌       | 50/199 [00:16<00:52,  2.85it/s]\u001b[A\n",
            " 26%|██▌       | 51/199 [00:16<00:51,  2.85it/s]\u001b[A\n",
            " 26%|██▌       | 52/199 [00:17<00:51,  2.84it/s]\u001b[A\n",
            " 27%|██▋       | 53/199 [00:17<00:51,  2.84it/s]\u001b[A\n",
            " 27%|██▋       | 54/199 [00:18<00:51,  2.84it/s]\u001b[A\n",
            " 28%|██▊       | 55/199 [00:18<00:50,  2.83it/s]\u001b[A\n",
            " 28%|██▊       | 56/199 [00:18<00:50,  2.83it/s]\u001b[A\n",
            " 29%|██▊       | 57/199 [00:19<00:50,  2.83it/s]\u001b[A\n",
            " 29%|██▉       | 58/199 [00:19<00:49,  2.82it/s]\u001b[A\n",
            " 30%|██▉       | 59/199 [00:19<00:49,  2.82it/s]\u001b[A\n",
            " 30%|███       | 60/199 [00:20<00:49,  2.83it/s]\u001b[A\n",
            " 31%|███       | 61/199 [00:20<00:48,  2.82it/s]\u001b[A\n",
            " 31%|███       | 62/199 [00:20<00:48,  2.82it/s]\u001b[A\n",
            " 32%|███▏      | 63/199 [00:21<00:48,  2.82it/s]\u001b[A\n",
            " 32%|███▏      | 64/199 [00:21<00:47,  2.82it/s]\u001b[A\n",
            " 33%|███▎      | 65/199 [00:21<00:47,  2.81it/s]\u001b[A\n",
            " 33%|███▎      | 66/199 [00:22<00:47,  2.81it/s]\u001b[A\n",
            " 34%|███▎      | 67/199 [00:22<00:47,  2.81it/s]\u001b[A\n",
            " 34%|███▍      | 68/199 [00:23<00:46,  2.80it/s]\u001b[A\n",
            " 35%|███▍      | 69/199 [00:23<00:46,  2.80it/s]\u001b[A\n",
            " 35%|███▌      | 70/199 [00:23<00:46,  2.80it/s]\u001b[A\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzNwNo7tlUUG"
      },
      "source": [
        "# %cd /content/\n",
        "with open(r\"LaBSE_embeddings.pkl\", \"wb\") as f:\n",
        "     pickle.dump(embeddings, f)"
      ],
      "id": "MzNwNo7tlUUG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfzkjnx_-jWR"
      },
      "source": [
        "# Release RAM\n",
        "\n",
        "#del labse\n",
        "#torch.cuda.empty_cache() \n",
        "gc.collect()"
      ],
      "id": "dfzkjnx_-jWR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp0bSUWlmVl1"
      },
      "source": [
        "# import io\n",
        "# !gdown https://drive.google.com/uc?id=1I83RSCTqHgw6dp1q7vLdr1ac_WfXOM5b \\\n",
        "# -O LaBSE_embeddings.pkl\n",
        "\n",
        "# with open(r\"LaBSE_embeddings.pkl\", \"rb\") as f:\n",
        "#     if torch.cuda.is_available():\n",
        "#         labse_embeddings = torch.load(f)\n",
        "#     else:\n",
        "#     # Doesnt work!\n",
        "#         labse_embeddings = torch.load(f, map_location=torch.device('cpu'))"
      ],
      "id": "dp0bSUWlmVl1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUNqtNIlsBrx"
      },
      "source": [
        "# Fully Connected Network"
      ],
      "id": "FUNqtNIlsBrx"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dried-tender"
      },
      "source": [
        "class DenseNetwork(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(DenseNetwork, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.middle_net = nn.Sequential(\n",
        "            nn.Linear(input_size * 2, input_size),  # (1536, 768)\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(input_size, input_size // 2), #(768, 384)\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(input_size // 2, input_size // 4),  #(384, 192),\n",
        "            nn.Softmax(dim=input_size // 4)\n",
        "            )\n",
        "        self.outer_net = nn.Sequential(\n",
        "            nn.Linear(input_size // 2, input_size // 4),  # (384, 192)\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(input_size // 4, input_size // 8), #(192, 96)\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(input_size // 8, input_size // 16),  #(96, 48)\n",
        "            nn.Relu(),\n",
        "            nn.Linear(input_size // 16, 1),  #(48, 1)\n",
        "            )\n",
        "\n",
        "    def forward(self, source, reference, translation):\n",
        "        x = torch.cat([source, reference], dim=1)\n",
        "        x = self.middle_net(x)\n",
        "        y = torch.cat([source, translation], dim=1)\n",
        "        y = self.middle_net(y)\n",
        "        z = torch.cat([x, y], dim=1)\n",
        "        return self.outer_net(z)"
      ],
      "id": "dried-tender",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87qTANpzMWq3"
      },
      "source": [
        "# TRAINING MODELS"
      ],
      "id": "87qTANpzMWq3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ip1l3bciQ8xK",
        "outputId": "6f562f2a-771e-4e9c-9296-9a83d47cc85e"
      },
      "source": [
        "%cd /content/\n",
        "%rm -rf radam.py\n",
        "\n",
        "!gdown https://drive.google.com/uc?id=1OpPRHftwAe_s6WHEJBkStmF2DAK6bM4v -O radam.py\n"
      ],
      "id": "ip1l3bciQ8xK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1OpPRHftwAe_s6WHEJBkStmF2DAK6bM4v\n",
            "To: /content/radam.py\n",
            "100% 11.8k/11.8k [00:00<00:00, 14.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evt4c6kDRfOw"
      },
      "source": [
        "from radam import RAdam, PlainRAdam, AdamW"
      ],
      "id": "evt4c6kDRfOw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c9nRpqONLj-"
      },
      "source": [
        "def load_data(pair):\n",
        "    \"\"\"\n",
        "    returns\n",
        "       tensors: source, reference, translation, labels\n",
        "    \"\"\"\n",
        "    # tensors (N, 768)\n",
        "    source = labse_embeddings[pair]['source']\n",
        "    reference = labse_embeddings[pair]['reference']\n",
        "    translation = labse_embeddings[pair]['translation']\n",
        "\n",
        "    labels =  torch.tensor(scores[pair]['avg-score'])\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        source = source.cuda()\n",
        "        reference = reference.cuda()\n",
        "        translation = translation.cuda()\n",
        "        labels = labels.cuda()\n",
        "        \n",
        "    return source, reference, translation, labels"
      ],
      "id": "4c9nRpqONLj-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ5VF97HTfH1"
      },
      "source": [
        "def train_model(pair,\n",
        "                epochs=200, batch_size=64, lr=0.01,\n",
        "                num_workers=0, log_interval=10):\n",
        "    # Loader parameters\n",
        "    pin_memory = True\n",
        "    if torch.cuda.is_available():\n",
        "        pin_memory = False\n",
        "    \n",
        "    params = {'batch_size': batch_size,\n",
        "                    'shuffle': True,\n",
        "                    'num_workers': num_workers,\n",
        "                    'pin_memory' : pin_memory\n",
        "          }\n",
        "\n",
        "    # load data\n",
        "    source, reference, translation, labels = load_data(pair)\n",
        "    \n",
        "    # train\n",
        "    dataset = TensorDataset(source, reference, translation, labels)\n",
        "    loader = DataLoader(dataset, **params)\n",
        "\n",
        "    # Initialize model\n",
        "    model = DenseNetwork(input_size=768)\n",
        "    model.train()\n",
        "    if torch.cuda.is_available():\n",
        "        model = model.cuda()\n",
        "\n",
        "    # Optimizer and Loss Criterion\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Training loop\n",
        "    summary = {'epoch' : [],\n",
        "               'train_loss' : [],\n",
        "               #'val_loss' : []\n",
        "               }\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for batch_idx, (src, ref, trs, target) in enumerate(loader):\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            output = model(src, ref, trs)\n",
        "            loss = criterion(output, target.unsqueeze(1).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if epoch % log_interval == 0:\n",
        "            print('Train Epoch: {} \\tLoss: {:.2f}'.format(\n",
        "                    epoch,\n",
        "                    loss.data,\n",
        "                    #val_loss.data\n",
        "                    ))\n",
        "            summary['epoch'].append(epoch)\n",
        "            summary['train_loss'].append(loss.data)\n",
        "            #summary['val_loss'].append(val_loss.data)\n",
        "\n",
        "    return model, summary"
      ],
      "id": "VQ5VF97HTfH1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb6Ca3vYSnam"
      },
      "source": [
        "# def train_model(pair,\n",
        "#                 epochs=200, batch_size=64, lr=0.01,\n",
        "#                 num_workers=0, log_interval=10):\n",
        "#     # Loader parameters\n",
        "#     pin_memory = True\n",
        "#     if torch.cuda.is_available():\n",
        "#         pin_memory = False\n",
        "    \n",
        "#     train_params = {'batch_size': batch_size,\n",
        "#                     'shuffle': True,\n",
        "#                     'num_workers': num_workers,\n",
        "#                     'pin_memory' : pin_memory\n",
        "#           }\n",
        "\n",
        "#     # load data\n",
        "#     source, reference, translation, labels = load_data(pair)\n",
        "    \n",
        "#     # train-val split\n",
        "#     dataset = TensorDataset(source, reference, translation, labels)\n",
        "#     train_size = int(0.9 * len(dataset))\n",
        "#     val_size = len(dataset) - train_size \n",
        "#     train, val = random_split(dataset, [train_size, val_size],\n",
        "#                               generator=torch.Generator())\n",
        "#     # train\n",
        "#     train_loader = DataLoader(train, **train_params)\n",
        "#     # validation\n",
        "#     val_params = {'batch_size': val_size,\n",
        "#                   'shuffle': True,\n",
        "#                   'num_workers': num_workers,\n",
        "#                   'pin_memory' : pin_memory\n",
        "#                  }\n",
        "#     val_loader = DataLoader(val, **val_params)\n",
        "#     for i, (src, ref, trs, target) in enumerate(val_loader):\n",
        "#         val_src, val_ref, val_trs, val_target = src, ref, trs, target\n",
        "\n",
        "#     # Initialize model\n",
        "#     model = DenseNetwork(input_size=768)\n",
        "#     model.train()\n",
        "#     if torch.cuda.is_available():\n",
        "#         model = model.cuda()\n",
        "\n",
        "#     # Optimizer and Loss Criterion\n",
        "#     optimizer = RAdam(model.parameters(), lr=lr)\n",
        "#     criterion = nn.MSELoss()\n",
        "\n",
        "#     # Training loop\n",
        "#     summary = {'epoch' : [],\n",
        "#                'train_loss' : [],\n",
        "#                'val_loss' : []\n",
        "#                }\n",
        "#     for epoch in range(epochs):\n",
        "#         for batch_idx, \\\n",
        "#          (tr_src, tr_ref, tr_trs, tr_target) in enumerate(train_loader):\n",
        "#             model.train()\n",
        "#             optimizer.zero_grad()\n",
        "#             output = model(tr_src, tr_ref, tr_trs)\n",
        "#             loss = criterion(output, tr_target.unsqueeze(1).float())\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "\n",
        "#             # Validation\n",
        "#             model.eval()\n",
        "#             with torch.no_grad():\n",
        "#                 val_output = model(val_src, val_ref, val_trs)\n",
        "#                 val_loss = criterion(val_output, val_target.unsqueeze(1).float())\n",
        "\n",
        "#         if epoch % log_interval == 0:\n",
        "#             print('Train Epoch: {} \\tLoss: {:.2f} \\tValidation Loss: {:.2f}'.format(\n",
        "#                     epoch,\n",
        "#                     loss.data,\n",
        "#                     val_loss.data\n",
        "#                     ))\n",
        "#             summary['epoch'].append(epoch)\n",
        "#             summary['train_loss'].append(loss.data)\n",
        "#             summary['val_loss'].append(val_loss.data)\n",
        "\n",
        "#     return model, summary"
      ],
      "id": "yb6Ca3vYSnam",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "P_JEixTtAzYf",
        "outputId": "58148167-4123-4233-a2c8-1641f33a5493"
      },
      "source": [
        "model_cs_en, summary = train_model('cs-en', epochs=1000, batch_size=64, lr=0.001)"
      ],
      "id": "P_JEixTtAzYf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-89c7662bd322>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_cs_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cs-en'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-fb6eada44b82>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(pair, epochs, batch_size, lr, num_workers, log_interval)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-3dccb14f2c82>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(pair)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# tensors (N, 768)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabse_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'source'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mreference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabse_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reference'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtranslation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabse_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'translation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'labse_embeddings' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "aB1VxQ30tJFk",
        "outputId": "03833e5d-7929-40e7-8ed4-91d8cf931995"
      },
      "source": [
        "plt.plot(summary['epoch'], summary['train_loss'])\n",
        "#plt.plot(summary['epoch'], summary['val_loss'])\n",
        "\n",
        "plt.show()"
      ],
      "id": "aB1VxQ30tJFk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWbDIEkDuV4X"
      },
      "source": [
        "# Predict"
      ],
      "id": "yWbDIEkDuV4X"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtZZsmnkmplf",
        "outputId": "08915ba7-2b98-43f7-f3e5-bc074d16cd79"
      },
      "source": [
        "model_cs_en.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    if torch.cuda.is_available():\n",
        "        output = model(source.cuda(), reference.cuda(), translation.cuda())\n",
        "    else:\n",
        "        output = model(source, reference, translation)\n",
        "\n",
        "output"
      ],
      "id": "HtZZsmnkmplf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[69.4778],\n",
              "        [69.4778],\n",
              "        [69.4778],\n",
              "        ...,\n",
              "        [69.4778],\n",
              "        [69.4778],\n",
              "        [69.4778]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cRax2_Cdz6h",
        "outputId": "8d0f0b70-0d8f-4ceb-9230-2f627b153ba5"
      },
      "source": [
        "labels"
      ],
      "id": "4cRax2_Cdz6h",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([60.0000, 44.0000, 96.5000,  ..., 32.0000, 76.0000, 55.0000],\n",
              "       device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    }
  ]
}