{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "velvet-watch",
   "metadata": {},
   "source": [
    "# Text Mining Group Project\n",
    "## EN-ZH test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-daughter",
   "metadata": {},
   "source": [
    "##### Notebook for the production of the test CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-laundry",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecological-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from rouge import Rouge\n",
    "import string\n",
    "from nltk.translate import chrf_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ongoing-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the best metric here.\n",
    "best_metric = \"chrf_b1_n210\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-music",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "qualified-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "touched-vector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22128 entries, 0 to 22127\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   source       22128 non-null  object\n",
      " 1   reference    22128 non-null  object\n",
      " 2   translation  22128 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 518.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "divided-peninsula",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The future and the destinies of the citizens o...</td>\n",
       "      <td>世界上每个国家公民的未来和命运日益联系在一起。</td>\n",
       "      <td>世界各国人民前途命运越来越紧密地联系在一起。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>After all that hard work, the finished result ...</td>\n",
       "      <td>经过那么多的努力，最终的结果现在已经可以揭晓了。</td>\n",
       "      <td>经过这么艰辛的工作，最终的结果现在才得以公布。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Author: researcher of Suning Institute of Fina...</td>\n",
       "      <td>作者：苏宁金融研究所研究员，财经专栏作家，财经评论员。</td>\n",
       "      <td>作者：苏宁金融研究院特约研究员，财经专栏作家，财经评论员。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“The Great Wall” tells the story of a Chinese ...</td>\n",
       "      <td>《长城》讲述了古代一支中国精锐部队在世界著名的中国长城上与怪物桃蒂英勇作战的故事。</td>\n",
       "      <td>《长城》讲述了在古代，一支中国精英部队为保卫人类，在举世闻名的长城上与怪兽饕餮进行生死决战的故事。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Our comrades from the Political Bureau should ...</td>\n",
       "      <td>政治局同志要学习历史，讲道理，不能混淆公、私利益，叫白黑，模糊义与利的界限，处理基于裙带关系...</td>\n",
       "      <td>中央政治局的同志都应该明史知理，不能颠倒了公私、混淆了是非、模糊了义利、放纵了亲情，要带头树...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  The future and the destinies of the citizens o...   \n",
       "1  After all that hard work, the finished result ...   \n",
       "2  Author: researcher of Suning Institute of Fina...   \n",
       "3  “The Great Wall” tells the story of a Chinese ...   \n",
       "4  Our comrades from the Political Bureau should ...   \n",
       "\n",
       "                                           reference  \\\n",
       "0                            世界上每个国家公民的未来和命运日益联系在一起。   \n",
       "1                           经过那么多的努力，最终的结果现在已经可以揭晓了。   \n",
       "2                        作者：苏宁金融研究所研究员，财经专栏作家，财经评论员。   \n",
       "3          《长城》讲述了古代一支中国精锐部队在世界著名的中国长城上与怪物桃蒂英勇作战的故事。   \n",
       "4  政治局同志要学习历史，讲道理，不能混淆公、私利益，叫白黑，模糊义与利的界限，处理基于裙带关系...   \n",
       "\n",
       "                                         translation  \n",
       "0                             世界各国人民前途命运越来越紧密地联系在一起。  \n",
       "1                            经过这么艰辛的工作，最终的结果现在才得以公布。  \n",
       "2                      作者：苏宁金融研究院特约研究员，财经专栏作家，财经评论员。  \n",
       "3  《长城》讲述了在古代，一支中国精英部队为保卫人类，在举世闻名的长城上与怪兽饕餮进行生死决战的故事。  \n",
       "4  中央政治局的同志都应该明史知理，不能颠倒了公私、混淆了是非、模糊了义利、放纵了亲情，要带头树...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-paris",
   "metadata": {},
   "source": [
    "---\n",
    "### PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "suitable-addiction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source\n",
      "      source reference translation\n",
      "8506       I       我是我           俺\n",
      "10022      I         i           俺\n",
      "11577      I         Ⅰ           俺\n",
      "Bad idx: [8506, 10022, 11577]\n",
      "reference\n",
      "          source reference translation\n",
      "3462   said that         说          说过\n",
      "10022          I         i           俺\n",
      "11577          I         Ⅰ           俺\n",
      "Bad idx: [3462, 10022, 11577]\n",
      "translation\n",
      "      source reference translation\n",
      "8506       I       我是我           俺\n",
      "10022      I         i           俺\n",
      "11577      I         Ⅰ           俺\n",
      "Bad idx: [8506, 10022, 11577]\n"
     ]
    }
   ],
   "source": [
    "# Check for empty or sparse reference / translation, and drop them.\n",
    "for column in [\"source\",\"reference\",\"translation\"]:\n",
    "    print(column)\n",
    "    bad_idx = [idx for idx in np.where(df1[column].str.len()<=1)[0]]\n",
    "    if bad_idx != []:\n",
    "        print(df1.iloc[bad_idx])\n",
    "    print(f\"Bad idx: {bad_idx}\")\n",
    "#    df1 = df1.drop(index=bad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "recovered-complement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3462</th>\n",
       "      <td>said that</td>\n",
       "      <td>说</td>\n",
       "      <td>说过</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8506</th>\n",
       "      <td>I</td>\n",
       "      <td>我是我</td>\n",
       "      <td>俺</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10022</th>\n",
       "      <td>I</td>\n",
       "      <td>i</td>\n",
       "      <td>俺</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11577</th>\n",
       "      <td>I</td>\n",
       "      <td>Ⅰ</td>\n",
       "      <td>俺</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          source reference translation\n",
       "3462   said that         说          说过\n",
       "8506           I       我是我           俺\n",
       "10022          I         i           俺\n",
       "11577          I         Ⅰ           俺"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.iloc[[3462,8506,10022,11577],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "nominated-toddler",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two dataframes. One is unprocessed, the other is preprocessed to remove punctuation and be lowercased.\n",
    "df_u = df1.copy()\n",
    "\n",
    "# For ZH, no preprocessing should be applied.\n",
    "    \n",
    "df_dict = {\"df_u\":df_u}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "figured-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize a scaler for later.\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-theta",
   "metadata": {},
   "source": [
    "---\n",
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-herald",
   "metadata": {},
   "source": [
    "--- \n",
    "Bleu Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "chronic-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_first_BLEU(reference,translation):\n",
    "    \"\"\"\n",
    "    Expects lists of strings for both reference and translation.\n",
    "    Returns the score \n",
    "    \"\"\"\n",
    "    \n",
    "    # Let word be every unique word in the translation.\n",
    "    # Can be done by setting up a Counter object.\n",
    "    t_c = Counter(word_tokenize(translation))\n",
    "    words = sorted(t_c)\n",
    "    \n",
    "    refs_c = Counter(word_tokenize(reference))\n",
    "    \n",
    "    # Let Covered be the minimum amt of times a word appears in the reference, compared to R(w).\n",
    "    # Let D(word) be how many times a unique word appears in the candidate translation.\n",
    "    # Let R(word) be the largest numer of times the word appears in any one reference.\n",
    "    \n",
    "    covered = 0\n",
    "    \n",
    "    for word in words:\n",
    "        covered += min(t_c[word],refs_c[word])\n",
    "\n",
    "    \n",
    "\n",
    "    # Let total be the number of words in translation.\n",
    "    total = sum(t_c.values())\n",
    "    \n",
    "    BLEU_score = covered / total\n",
    "    \n",
    "    return BLEU_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "premium-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_scores_list = [\"basic bleu\"]\n",
    "\n",
    "for df in list(df_dict.values()):\n",
    "    for key in bleu_scores_list:\n",
    "        # Apply the function to get a column of the scores.\n",
    "        df[(key+\" score\")] = df.apply(lambda row: my_first_BLEU(row[\"reference\"],row[\"translation\"]),axis=1)\n",
    "        # Also add a z score column.\n",
    "        df[(key+ \"_zscore\")] = scaler.fit_transform(df[(key+\" score\")].to_numpy().reshape(-1,1)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-limit",
   "metadata": {},
   "source": [
    "---\n",
    "Rouge metric as described in\n",
    "\n",
    "https://towardsdatascience.com/the-ultimate-performance-metric-in-nlp-111df6c64460\n",
    "\n",
    "And\n",
    "https://pypi.org/project/rouge-metric/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "coated-austin",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "interpreted-emphasis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'f': 0.0, 'p': 0.0, 'r': 0.0},\n",
       "  'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0},\n",
       "  'rouge-l': {'f': 0.0, 'p': 0.0, 'r': 0.0}}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example Cell\n",
    "model_out = df1[\"translation\"][0]\n",
    "reference = df1[\"reference\"][0]\n",
    "# The get scores method returns three metrics, F1 score, p precision and recall r.\n",
    "# For each unigram,bigram and Longest sequence.\n",
    "rouge.get_scores(model_out,reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "awful-result",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scores.\n",
    "# For every df considered;\n",
    "for df in list(df_dict.values()):\n",
    "    # For the entire model, model_out and reference need to be lists of strings.\n",
    "    model_out = df[\"translation\"].to_list()\n",
    "    reference = df[\"reference\"].to_list()\n",
    "    rouge_scores = rouge.get_scores(model_out,reference)\n",
    "    # For each of the scores calculated, output a new column in the df with the f1 scores.\n",
    "    for key in rouge_scores[0].keys():\n",
    "        df[(key+\" score\")] = pd.Series([score[key][\"f\"] for score in rouge_scores])\n",
    "        # Also add a z score column.\n",
    "        df[(key+ \"_zscore\")] = scaler.fit_transform(df[(key+\" score\")].to_numpy().reshape(-1,1)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-collar",
   "metadata": {},
   "source": [
    "---\n",
    "#### chrF metric\n",
    "\n",
    "Check the paper here: https://www.aclweb.org/anthology/W15-3049.pdf\n",
    "\n",
    "The general formula for the CHRF score is:\n",
    "\n",
    "`CHRFBeta = (1 + Beta**2) * ((chrP * chrR) / (Beta**2*chrP + chrR))`\n",
    "\n",
    "where:\n",
    "* chrP is the percentage of n-grams in the hypothesis which have a counterpart in the reference.\n",
    "* chrR is the percentage of character n-grams in the reference which are also present in the hypothesis.\n",
    "* Beta is a parameter which assigns beta times more importance to recall than to precision (if beta == 1, they have the same importance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "spatial-amplifier",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-2aa7ef8b079e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mappend_str\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;34m\"_zscore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mappend_str\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mdf_p\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mchrf_scores\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_p' is not defined"
     ]
    }
   ],
   "source": [
    "# The default n-gram values are min == 1, max == 6. \n",
    "# The default beta is 3.\n",
    "\n",
    "# Moreover, it is worthwhile to mention chrf uses its own tokenization with whitespaces.\n",
    "# Note: this takes a few minutes to run.\n",
    "min_len = [1,2]\n",
    "max_len = [6,10]\n",
    "beta = [1,3]\n",
    "\n",
    "for df in list(df_dict.values()):\n",
    "    chrf_scores=[]\n",
    "    for min_l in min_len:\n",
    "        for max_l in max_len:\n",
    "            for b in beta:\n",
    "                append_str = \"chrf_b\" + str(b) + \"_n\" + str(min_l) + str(max_l)\n",
    "                chrf_scores.append(append_str)\n",
    "                df[append_str] = df.apply(lambda row: chrf_score.sentence_chrf(row[\"reference\"],row[\"translation\"],min_len=min_l,max_len=max_l,beta=b),axis=1)\n",
    "                # Also add a z score column.\n",
    "                df[(append_str+ \"_zscore\")] = scaler.fit_transform(df[append_str].to_numpy().reshape(-1,1)).flatten()\n",
    "\n",
    "df_u.loc[:,chrf_scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-addition",
   "metadata": {},
   "source": [
    "---\n",
    "### Producing the testset CSV\n",
    "Given the produced scores, choose the ones to apply to the CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "anonymous-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use either the zscore or the non-standardized scores. \n",
    "# Also note either df_u or df_p choice.\n",
    "df1[\"metric\"]=df_u[best_metric+\"_zscore\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "british-assist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The future and the destinies of the citizens o...</td>\n",
       "      <td>世界上每个国家公民的未来和命运日益联系在一起。</td>\n",
       "      <td>世界各国人民前途命运越来越紧密地联系在一起。</td>\n",
       "      <td>-0.495923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>After all that hard work, the finished result ...</td>\n",
       "      <td>经过那么多的努力，最终的结果现在已经可以揭晓了。</td>\n",
       "      <td>经过这么艰辛的工作，最终的结果现在才得以公布。</td>\n",
       "      <td>-0.065094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Author: researcher of Suning Institute of Fina...</td>\n",
       "      <td>作者：苏宁金融研究所研究员，财经专栏作家，财经评论员。</td>\n",
       "      <td>作者：苏宁金融研究院特约研究员，财经专栏作家，财经评论员。</td>\n",
       "      <td>3.412354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“The Great Wall” tells the story of a Chinese ...</td>\n",
       "      <td>《长城》讲述了古代一支中国精锐部队在世界著名的中国长城上与怪物桃蒂英勇作战的故事。</td>\n",
       "      <td>《长城》讲述了在古代，一支中国精英部队为保卫人类，在举世闻名的长城上与怪兽饕餮进行生死决战的故事。</td>\n",
       "      <td>-0.182110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Our comrades from the Political Bureau should ...</td>\n",
       "      <td>政治局同志要学习历史，讲道理，不能混淆公、私利益，叫白黑，模糊义与利的界限，处理基于裙带关系...</td>\n",
       "      <td>中央政治局的同志都应该明史知理，不能颠倒了公私、混淆了是非、模糊了义利、放纵了亲情，要带头树...</td>\n",
       "      <td>-0.782331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  The future and the destinies of the citizens o...   \n",
       "1  After all that hard work, the finished result ...   \n",
       "2  Author: researcher of Suning Institute of Fina...   \n",
       "3  “The Great Wall” tells the story of a Chinese ...   \n",
       "4  Our comrades from the Political Bureau should ...   \n",
       "\n",
       "                                           reference  \\\n",
       "0                            世界上每个国家公民的未来和命运日益联系在一起。   \n",
       "1                           经过那么多的努力，最终的结果现在已经可以揭晓了。   \n",
       "2                        作者：苏宁金融研究所研究员，财经专栏作家，财经评论员。   \n",
       "3          《长城》讲述了古代一支中国精锐部队在世界著名的中国长城上与怪物桃蒂英勇作战的故事。   \n",
       "4  政治局同志要学习历史，讲道理，不能混淆公、私利益，叫白黑，模糊义与利的界限，处理基于裙带关系...   \n",
       "\n",
       "                                         translation    metric  \n",
       "0                             世界各国人民前途命运越来越紧密地联系在一起。 -0.495923  \n",
       "1                            经过这么艰辛的工作，最终的结果现在才得以公布。 -0.065094  \n",
       "2                      作者：苏宁金融研究院特约研究员，财经专栏作家，财经评论员。  3.412354  \n",
       "3  《长城》讲述了在古代，一支中国精英部队为保卫人类，在举世闻名的长城上与怪兽饕餮进行生死决战的故事。 -0.182110  \n",
       "4  中央政治局的同志都应该明史知理，不能颠倒了公私、混淆了是非、模糊了义利、放纵了亲情，要带头树... -0.782331  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "arabic-literacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"scores.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-shopper",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
