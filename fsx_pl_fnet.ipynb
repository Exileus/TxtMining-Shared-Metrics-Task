{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch related imports\n",
    "import torch\n",
    "from torch.nn import *\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# PyTorch Lightning related imports\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "# metrics\n",
    "from torchmetrics.functional import mean_absolute_error, mean_squared_error\n",
    "from metrics.regression_metrics import t_kendalltau, t_pearson, t_spearman\n",
    "\n",
    "# fnet architecture & RAdam\n",
    "from fnet.model import FNet\n",
    "from radam.radam import RAdam\n",
    "\n",
    "# Custom datamodule\n",
    "from datamodules.tm_datamodule import TextMiningDataModule\n",
    "\n",
    "# weights and biases // not working // disabled\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "# ModelCheckpoint fails. Tutorial outdated. \n",
    "# Leaving here for improvements in the future\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "srt = [\"source\", \"reference\", \"translation\"]\n",
    "language_pairs = [\n",
    "    \"cs-en\",\n",
    "    \"de-en\",\n",
    "    \"en-fi\",\n",
    "    \"en-zh\",\n",
    "    \"ru-en\",\n",
    "    \"zh-en\",\n",
    "]\n",
    "scores = {pair: pd.read_csv(f\"corpus/{pair}/scores.csv\") for pair in language_pairs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = \"de-en\"\n",
    "embedding_ref = torch.from_numpy(np.load(f\"corpus/{pair}/laser.reference_embeds.npy\")).float()\n",
    "embedding_src = torch.from_numpy(np.load(f\"corpus/{pair}/laser.source_embeds.npy\")).float()\n",
    "embedding_hyp = torch.from_numpy(np.load(f\"corpus/{pair}/laser.translation_embeds.npy\")).float()\n",
    "score = torch.tensor(scores[pair][\"z-score\"]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21704])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(monitor='val_loss', patience=5, verbose=False, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationPredictionLogger(Callback):\n",
    "    def __init__(self, val_samples, num_samples=32):\n",
    "        super().__init__()\n",
    "        self.num_samples = num_samples\n",
    "        self.val_imgs, self.val_score = val_samples\n",
    "\n",
    "    def on_validation_batch_end(\n",
    "        self, trainer, pl_module,\n",
    "    ):\n",
    "        val_imgs = self.val_imgs.to(device=pl_module.device)\n",
    "        val_score = self.val_score.to(device=pl_module.device)\n",
    "\n",
    "        predictions = pl_module(val_imgs)\n",
    "        trainer.logger.experiment.log(\n",
    "            {\n",
    "                \"examples\": [\n",
    "                    wandb.Image(x, caption=f\"Prediction:{p}, Score: {y}\")\n",
    "                    for x, p, y in zip(\n",
    "                        val_imgs[: self.num_samples],\n",
    "                        predictions[: self.num_samples],\n",
    "                        val_score[: self.num_samples],\n",
    "                    )\n",
    "                ]\n",
    "            }\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_1 = 64\n",
    "FEATURES_2 = FEATURES_1 * 2\n",
    "FEATURES_3 = FEATURES_2 * 2\n",
    "FEATURES_4 = FEATURES_3 * 2\n",
    "FEATURES_5 = FEATURES_4 * 2\n",
    "\n",
    "class Model(pl.LightningModule):\n",
    "    def __init__(self, input_shape, learning_rate=0.001):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.c1 = Conv2d(3, FEATURES_1, (3, 1), 1, (1, 0))\n",
    "        self.c2 = Conv2d(FEATURES_1, FEATURES_1, (3, 1), 1, (1, 0)) # 32\n",
    "        self.c3 = Conv2d(FEATURES_1, FEATURES_2, (3, 1), 4, (1, 0)) # 24\n",
    "        self.c4 = Conv2d(FEATURES_2, FEATURES_3, (3, 1), 2, (1, 0)) # 16\n",
    "        self.c5 = Conv2d(FEATURES_3, FEATURES_4, (3, 1), 2, (1, 0)) # 8\n",
    "        self.c6 = Conv2d(FEATURES_4, FEATURES_5, (3, 1), 2, (1, 0)) # 2\n",
    "        self.bn = BatchNorm2d(FEATURES_1)\n",
    "        self.bn3 = BatchNorm2d(FEATURES_2)\n",
    "        self.bn4 = BatchNorm2d(FEATURES_3)\n",
    "        self.bn5 = BatchNorm2d(FEATURES_4)\n",
    "        self.bn6 = BatchNorm2d(FEATURES_5)\n",
    "        self.fc1 = Linear(32 * FEATURES_5, 256)\n",
    "        self.fc2 = Linear(256, 64)\n",
    "        self.fc3 = Linear(64, 1)\n",
    "\n",
    "    def _forward_features(self, x):\n",
    "        x = self.bn(F.relu(self.c1(x)))\n",
    "        # x = self.bn(F.relu(self.c2(x) + x))\n",
    "        # x = self.bn(F.relu(self.c2(x) + x))\n",
    "        # x = self.bn(F.relu(self.c2(x) + x))\n",
    "        x = self.bn(F.relu(self.c2(x)))\n",
    "        x = self.bn3(F.relu(self.c3(x)))\n",
    "        x = self.bn4(F.relu(self.c4(x)))\n",
    "        x = self.bn5(F.relu(self.c5(x)))\n",
    "        # x = self.bn6(F.relu(self.c6(x)))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        # print(x.shape)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.mse_loss(logits, y)\n",
    "        mse = mean_squared_error(logits, y)\n",
    "        mae = mean_absolute_error(logits, y)\n",
    "        k = t_kendalltau(logits, y)\n",
    "        p = t_pearson(logits, y)\n",
    "        s = t_spearman(logits, y)\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log(\"train_mse\", mse, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log(\"train_mae\", mae, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log(\"train_kendalltau\", k, on_step=False, on_epoch=True, logger=True)\n",
    "        self.log(\"train_pearson\", p, on_step=False, on_epoch=True, logger=True)\n",
    "        self.log(\"train_spearman\", s, on_step=False, on_epoch=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.mse_loss(logits, y)\n",
    "        mse = mean_squared_error(logits, y)\n",
    "        mae = mean_absolute_error(logits, y)\n",
    "        k = t_kendalltau(logits, y)\n",
    "        p = t_pearson(logits, y)\n",
    "        s = t_spearman(logits, y)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_mse\", mse, prog_bar=True)\n",
    "        self.log(\"val_mae\", mae, prog_bar=True)\n",
    "        self.log(\"val_kendalltau\", k, on_step=False, prog_bar=True)\n",
    "        self.log(\"val_pearson\", p, on_step=False, prog_bar=True)\n",
    "        self.log(\"val_spearman\", s, on_step=False, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.mse_loss(logits, y)\n",
    "        mse = mean_squared_error(logits, y)\n",
    "        mae = mean_absolute_error(logits, y)\n",
    "        k = t_kendalltau(logits, y)\n",
    "        p = t_pearson(logits, y)\n",
    "        s = t_spearman(logits, y)\n",
    "        self.log(\"test_loss\", loss, on_step=True, prog_bar=True)\n",
    "        self.log(\"test_mse\", mse, on_step=True, prog_bar=True)\n",
    "        self.log(\"test_mae\", mae, on_step=True, prog_bar=True)\n",
    "        self.log(\"test_kendalltau\", k, prog_bar=True)\n",
    "        self.log(\"test_pearson\", p, prog_bar=True)\n",
    "        self.log(\"test_spearman\", s, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FourierTransformerDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape,\n",
    "        learning_rate=0.001,\n",
    "        num_layers: int = 6,\n",
    "        dropout: float = 0.1,\n",
    "        dim_ff:int = 2048\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.decoder = FNet(num_layers, input_shape, dim_ff, dropout)\n",
    "        self.fc_bloc = Sequential(\n",
    "            Linear(input_shape, input_shape // (div := 2)),  # 1024 > 512\n",
    "            GELU(),\n",
    "            Dropout(dropout),\n",
    "            Linear(input_shape // div, input_shape // (div := div * 4)),  # 512 > 128\n",
    "            GELU(),\n",
    "            Dropout(dropout),\n",
    "            Linear(input_shape // div, 1),  # 128 > 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.decoder(x)\n",
    "        x = self.fc_bloc(x)\n",
    "        x = torch.tanh(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.mse_loss(logits, y)\n",
    "        mse = mean_squared_error(logits, y)\n",
    "        mae = mean_absolute_error(logits, y)\n",
    "        k = t_kendalltau(logits, y)\n",
    "        p = t_pearson(logits, y)\n",
    "        s = t_spearman(logits, y)\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log(\"train_mse\", mse, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log(\"train_mae\", mae, on_step=True, on_epoch=True, logger=True)\n",
    "        # self.log(\"train_kendalltau\", k, on_step=False, on_epoch=True, logger=True)\n",
    "        # self.log(\"train_pearson\", p, on_step=False, on_epoch=True, logger=True)\n",
    "        # self.log(\"train_spearman\", s, on_step=False, on_epoch=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.mse_loss(logits, y)\n",
    "        mse = mean_squared_error(logits, y)\n",
    "        mae = mean_absolute_error(logits, y)\n",
    "        k = t_kendalltau(logits, y)\n",
    "        p = t_pearson(logits, y)\n",
    "        s = t_spearman(logits, y)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_mse\", mse, prog_bar=True)\n",
    "        self.log(\"val_mae\", mae, prog_bar=True)\n",
    "        self.log(\"val_kendalltau\", k, on_step=False, prog_bar=True)\n",
    "        self.log(\"val_pearson\", p, on_step=False, prog_bar=True)\n",
    "        self.log(\"val_spearman\", s, on_step=False, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.mse_loss(logits, y)\n",
    "        mse = mean_squared_error(logits, y)\n",
    "        mae = mean_absolute_error(logits, y)\n",
    "        k = t_kendalltau(logits, y)\n",
    "        p = t_pearson(logits, y)\n",
    "        s = t_spearman(logits, y)\n",
    "        self.log(\"test_loss\", loss, on_step=True, prog_bar=True)\n",
    "        self.log(\"test_mse\", mse, on_step=True, prog_bar=True)\n",
    "        self.log(\"test_mae\", mae, on_step=True, prog_bar=True)\n",
    "        self.log(\"test_kendalltau\", k, prog_bar=True)\n",
    "        self.log(\"test_pearson\", p, prog_bar=True)\n",
    "        self.log(\"test_spearman\", s, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        optimizer = RAdam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training + Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (decoder): FNet(\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=3072, out_features=256, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=256, out_features=3072, bias=True)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (norm1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (norm2): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=3072, out_features=256, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=256, out_features=3072, bias=True)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (norm1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (norm2): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=3072, out_features=256, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=256, out_features=3072, bias=True)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (norm1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (norm2): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=3072, out_features=256, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=256, out_features=3072, bias=True)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (norm1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (norm2): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_bloc): Sequential(\n",
       "    (0): Linear(in_features=3072, out_features=1536, bias=True)\n",
       "    (1): GELU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "    (4): GELU()\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "    (6): Linear(in_features=384, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair = \"de-en\"\n",
    "num_layers = 4  # 2 best results\n",
    "dim_ff = 256  # 256 best results\n",
    "lr = 0.00005  # 0.0001 best results\n",
    "dm = TextMiningDataModule(16, pair, 1024 * 3)\n",
    "dm.setup()\n",
    "model = Model(dm.dims, learning_rate=lr, num_layers=4, dim_ff=dim_ff)\n",
    "# wandb_logger = WandbLogger(project=\"wandb-lightning\", job_type=\"train\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_kendalltau\",\n",
    "    filename=f\"{pair}\"+\"_{epoch:02d}_{val_kendalltau:.3f}\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    progress_bar_refresh_rate=1,\n",
    "    gpus=1,\n",
    "    logger=False,\n",
    "    # checkpoint_callback=False\n",
    "    # logger=wandb_logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    ")\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | decoder | FNet       | 6.4 M \n",
      "1 | fc_bloc | Sequential | 5.3 M \n",
      "---------------------------------------\n",
      "11.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.7 M    Total params\n",
      "46.659    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1357/1357 [00:29<00:00, 45.68it/s, loss=0.6, val_loss=0.696, val_mse=0.696, val_mae=0.647, val_kendalltau=0.231, val_pearson=0.325, val_spearman=0.322]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dm)\n",
    "trainer.save_checkpoint(f\"{pair}_{time.time()}.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "results = []\n",
    "i = 1000\n",
    "\n",
    "for test_emb, test_score in dm.test_dataloader():\n",
    "    results += (model(test_emb).detach().cpu().numpy().tolist())\n",
    "\n",
    "np.savetxt(f\"scores_{pair}.csv\", np.array(results).flatten(), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = {pair: pd.read_csv(f\"testset/{pair}/scores.csv\") for pair in language_pairs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Das Publikum ist fast gleichmäßig zwischen Sch...</td>\n",
       "      <td>The audience is almost evenly split between bl...</td>\n",
       "      <td>The audience is almost evenly split between bl...</td>\n",
       "      <td>2.764301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Du kannst ihre Energie durch den Bildschirm sp...</td>\n",
       "      <td>You can feel their energy through the screen. \"\"</td>\n",
       "      <td>You can feel her energy through the screen.\"</td>\n",
       "      <td>1.287924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Da die Adresse unbekannt ist, wird die Mithilf...</td>\n",
       "      <td>As the address is unknown, the help of the pop...</td>\n",
       "      <td>As the address is unknown, the assistance of t...</td>\n",
       "      <td>1.499944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Arsenal-Manager Arsene Wenger, dessen Verein i...</td>\n",
       "      <td>Arsenal manager Arsene Wenger, whose club is o...</td>\n",
       "      <td>Arsenal manager Arsene Wenger, whose club is o...</td>\n",
       "      <td>2.764301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Landwirtschaftsminister im Interview - Wie sch...</td>\n",
       "      <td>Agriculture Minister in the interview - How do...</td>\n",
       "      <td>Minister of Agriculture in interview – How do ...</td>\n",
       "      <td>0.204494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28399</th>\n",
       "      <td>28399</td>\n",
       "      <td>Insgesamt gebe es jedoch seit rund 30 Jahren e...</td>\n",
       "      <td>Total, however, there were approximately 30 ye...</td>\n",
       "      <td>Nevertheless, altogether, there have been a se...</td>\n",
       "      <td>-0.811066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28400</th>\n",
       "      <td>28400</td>\n",
       "      <td>Wir können froh sein, dass wir diese Zeit läng...</td>\n",
       "      <td>We can be glad we have overcome these time alr...</td>\n",
       "      <td>We can be glad that we have long overcome this...</td>\n",
       "      <td>-0.629707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28401</th>\n",
       "      <td>28401</td>\n",
       "      <td>Der unheilbare Zustand, der in den USA rund 1,...</td>\n",
       "      <td>The condition of unheilbare, which affects the...</td>\n",
       "      <td>The incurable condition, which affects around ...</td>\n",
       "      <td>-0.945399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28402</th>\n",
       "      <td>28402</td>\n",
       "      <td>\"Komfort Check-in\" nennt die Bahn die Fahrkart...</td>\n",
       "      <td>\"Check-in amenities,\" the rail operator descri...</td>\n",
       "      <td>The railway is calling this conductorless tick...</td>\n",
       "      <td>-1.990388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28403</th>\n",
       "      <td>28403</td>\n",
       "      <td>Anleger erreichen Renditen, wenn ihre Portfoli...</td>\n",
       "      <td>Investors reach valuations if their Portfolio-...</td>\n",
       "      <td>Investors achieve returns when their portfolio...</td>\n",
       "      <td>-1.579979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28404 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                             source  \\\n",
       "0               0  Das Publikum ist fast gleichmäßig zwischen Sch...   \n",
       "1               1  Du kannst ihre Energie durch den Bildschirm sp...   \n",
       "2               2  Da die Adresse unbekannt ist, wird die Mithilf...   \n",
       "3               3  Arsenal-Manager Arsene Wenger, dessen Verein i...   \n",
       "4               4  Landwirtschaftsminister im Interview - Wie sch...   \n",
       "...           ...                                                ...   \n",
       "28399       28399  Insgesamt gebe es jedoch seit rund 30 Jahren e...   \n",
       "28400       28400  Wir können froh sein, dass wir diese Zeit läng...   \n",
       "28401       28401  Der unheilbare Zustand, der in den USA rund 1,...   \n",
       "28402       28402  \"Komfort Check-in\" nennt die Bahn die Fahrkart...   \n",
       "28403       28403  Anleger erreichen Renditen, wenn ihre Portfoli...   \n",
       "\n",
       "                                               reference  \\\n",
       "0      The audience is almost evenly split between bl...   \n",
       "1       You can feel their energy through the screen. \"\"   \n",
       "2      As the address is unknown, the help of the pop...   \n",
       "3      Arsenal manager Arsene Wenger, whose club is o...   \n",
       "4      Agriculture Minister in the interview - How do...   \n",
       "...                                                  ...   \n",
       "28399  Total, however, there were approximately 30 ye...   \n",
       "28400  We can be glad we have overcome these time alr...   \n",
       "28401  The condition of unheilbare, which affects the...   \n",
       "28402  \"Check-in amenities,\" the rail operator descri...   \n",
       "28403  Investors reach valuations if their Portfolio-...   \n",
       "\n",
       "                                             translation    metric  \n",
       "0      The audience is almost evenly split between bl...  2.764301  \n",
       "1           You can feel her energy through the screen.\"  1.287924  \n",
       "2      As the address is unknown, the assistance of t...  1.499944  \n",
       "3      Arsenal manager Arsene Wenger, whose club is o...  2.764301  \n",
       "4      Minister of Agriculture in interview – How do ...  0.204494  \n",
       "...                                                  ...       ...  \n",
       "28399  Nevertheless, altogether, there have been a se... -0.811066  \n",
       "28400  We can be glad that we have long overcome this... -0.629707  \n",
       "28401  The incurable condition, which affects around ... -0.945399  \n",
       "28402  The railway is calling this conductorless tick... -1.990388  \n",
       "28403  Investors achieve returns when their portfolio... -1.579979  \n",
       "\n",
       "[28404 rows x 5 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores[\"de-en\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([[-9.1613717e-03],\n",
       "              [-1.2315828e-01],\n",
       "              [ 1.5249759e-01],\n",
       "              [ 2.9827762e-01],\n",
       "              [ 1.8509631e-01],\n",
       "              [ 4.9634852e-02],\n",
       "              [-4.4969472e-01],\n",
       "              [-6.8793494e-01],\n",
       "              [ 5.8158837e-02],\n",
       "              [-6.0465139e-01],\n",
       "              [ 1.1201333e-01],\n",
       "              [-4.3616255e-04],\n",
       "              [ 1.6160364e-01],\n",
       "              [ 4.0735242e-01],\n",
       "              [ 2.5897461e-01],\n",
       "              [-7.5041703e-03]], dtype=float32),\n",
       "       array([[ 0.28417528],\n",
       "              [ 0.11135941],\n",
       "              [-0.2411364 ],\n",
       "              [-0.00213673],\n",
       "              [ 0.08225336],\n",
       "              [ 0.15491392],\n",
       "              [-0.12357191],\n",
       "              [-0.01498444],\n",
       "              [ 0.07161871],\n",
       "              [ 0.15485623],\n",
       "              [ 0.17278703],\n",
       "              [-0.04378385],\n",
       "              [ 0.22395141],\n",
       "              [ 0.07993133],\n",
       "              [ 0.39238593],\n",
       "              [ 0.3087611 ]], dtype=float32),\n",
       "       array([[ 0.02768425],\n",
       "              [ 0.07862813],\n",
       "              [ 0.5522712 ],\n",
       "              [ 0.0420564 ],\n",
       "              [ 0.32978547],\n",
       "              [ 0.4197327 ],\n",
       "              [ 0.10623963],\n",
       "              [ 0.42848384],\n",
       "              [ 0.05126143],\n",
       "              [ 0.49218464],\n",
       "              [ 0.56589395],\n",
       "              [ 0.20138381],\n",
       "              [-0.01099278],\n",
       "              [ 0.21632698],\n",
       "              [-0.7346131 ],\n",
       "              [ 0.27692366]], dtype=float32), ...,\n",
       "       array([[ 0.19683923],\n",
       "              [-0.25459927],\n",
       "              [-0.29795772],\n",
       "              [-0.21552257],\n",
       "              [ 0.04154168],\n",
       "              [ 0.1137677 ],\n",
       "              [ 0.24254178],\n",
       "              [-0.01568637],\n",
       "              [ 0.33697134],\n",
       "              [-0.06786345],\n",
       "              [ 0.22407351],\n",
       "              [ 0.05075232],\n",
       "              [ 0.2918993 ],\n",
       "              [-0.39015305],\n",
       "              [ 0.02369403],\n",
       "              [-0.3803822 ]], dtype=float32),\n",
       "       array([[ 0.10649573],\n",
       "              [ 0.36663392],\n",
       "              [-0.19005069],\n",
       "              [ 0.09572414],\n",
       "              [ 0.02844584],\n",
       "              [ 0.29734427],\n",
       "              [ 0.04386545],\n",
       "              [-0.14536753],\n",
       "              [ 0.1567829 ],\n",
       "              [ 0.18232906],\n",
       "              [ 0.03101202],\n",
       "              [ 0.16647892],\n",
       "              [ 0.30010787],\n",
       "              [-0.34596312],\n",
       "              [-0.13435291],\n",
       "              [ 0.02340873]], dtype=float32),\n",
       "       array([[ 0.6007894 ],\n",
       "              [ 0.06836442],\n",
       "              [ 0.17470063],\n",
       "              [-0.04296054]], dtype=float32)], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(results, dtype=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of radam.radam failed: Traceback (most recent call last):\n",
      "  File \"/home/fsx/miniconda3/envs/pl/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/fsx/miniconda3/envs/pl/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 410, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/fsx/miniconda3/envs/pl/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/fsx/miniconda3/envs/pl/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 302, in update_class\n",
      "    if update_generic(old_obj, new_obj): continue\n",
      "  File \"/home/fsx/miniconda3/envs/pl/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/fsx/miniconda3/envs/pl/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 266, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: step() requires a code object with 1 free vars, not 0\n",
      "]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{'val_kendalltau': 0.09496324509382248,\n",
      " 'val_loss': 0.7278435826301575,\n",
      " 'val_mae': 0.6904030442237854,\n",
      " 'val_mse': 0.7278435826301575,\n",
      " 'val_pearson': 0.14763259887695312,\n",
      " 'val_spearman': 0.14055135846138}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.7278435826301575,\n",
       "  'val_mse': 0.7278435826301575,\n",
       "  'val_mae': 0.6904030442237854,\n",
       "  'val_kendalltau': 0.09496324509382248,\n",
       "  'val_pearson': 0.14763259887695312,\n",
       "  'val_spearman': 0.14055135846138}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f8b00cba333cbc52f2b9024e2fd0f03f267bd4c88e752638d58a81ffee90e795"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('pl': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}