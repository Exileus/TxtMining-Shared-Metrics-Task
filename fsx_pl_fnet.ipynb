{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch related imports\n",
    "import torch\n",
    "from torch.nn import *\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# PyTorch Lightning related imports\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "# metrics\n",
    "from torchmetrics.functional import mean_absolute_error, mean_squared_error\n",
    "from metrics.regression_metrics import t_kendalltau, t_pearson, t_spearman\n",
    "\n",
    "# fnet architecture & RAdam\n",
    "from fnet.model import FNet\n",
    "from radam.radam import RAdam\n",
    "\n",
    "# Custom datamodule\n",
    "from datamodules.tm_datamodule import TextMiningDataModule\n",
    "\n",
    "# weights and biases // not working // disabled\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "# ModelCheckpoint fails. Tutorial outdated. \n",
    "# Leaving here for improvements in the future\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "srt = [\"source\", \"reference\", \"translation\"]\n",
    "language_pairs = [\n",
    "    \"cs-en\",\n",
    "    \"de-en\",\n",
    "    \"en-fi\",\n",
    "    \"en-zh\",\n",
    "    \"ru-en\",\n",
    "    \"zh-en\",\n",
    "]\n",
    "scores = {pair: pd.read_csv(f\"corpus/{pair}/scores.csv\") for pair in language_pairs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = \"de-en\"\n",
    "embedding_ref = torch.from_numpy(np.load(f\"corpus/{pair}/laser.reference_embeds.npy\")).float()\n",
    "embedding_src = torch.from_numpy(np.load(f\"corpus/{pair}/laser.source_embeds.npy\")).float()\n",
    "embedding_hyp = torch.from_numpy(np.load(f\"corpus/{pair}/laser.translation_embeds.npy\")).float()\n",
    "score = torch.tensor(scores[pair][\"z-score\"]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21704])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(monitor='val_loss', patience=5, verbose=False, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationPredictionLogger(Callback):\n",
    "    def __init__(self, val_samples, num_samples=32):\n",
    "        super().__init__()\n",
    "        self.num_samples = num_samples\n",
    "        self.val_imgs, self.val_score = val_samples\n",
    "\n",
    "    def on_validation_batch_end(\n",
    "        self, trainer, pl_module,\n",
    "    ):\n",
    "        val_imgs = self.val_imgs.to(device=pl_module.device)\n",
    "        val_score = self.val_score.to(device=pl_module.device)\n",
    "\n",
    "        predictions = pl_module(val_imgs)\n",
    "        trainer.logger.experiment.log(\n",
    "            {\n",
    "                \"examples\": [\n",
    "                    wandb.Image(x, caption=f\"Prediction:{p}, Score: {y}\")\n",
    "                    for x, p, y in zip(\n",
    "                        val_imgs[: self.num_samples],\n",
    "                        predictions[: self.num_samples],\n",
    "                        val_score[: self.num_samples],\n",
    "                    )\n",
    "                ]\n",
    "            }\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_1 = 64\n",
    "FEATURES_2 = FEATURES_1 * 2\n",
    "FEATURES_3 = FEATURES_2 * 2\n",
    "FEATURES_4 = FEATURES_3 * 2\n",
    "FEATURES_5 = FEATURES_4 * 2\n",
    "\n",
    "class Model(pl.LightningModule):\n",
    "    def __init__(self, input_shape, learning_rate=0.001):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.c1 = Conv2d(3, FEATURES_1, (3, 1), 1, (1, 0))\n",
    "        self.c2 = Conv2d(FEATURES_1, FEATURES_1, (3, 1), 1, (1, 0)) # 32\n",
    "        self.c3 = Conv2d(FEATURES_1, FEATURES_2, (3, 1), 4, (1, 0)) # 24\n",
    "        self.c4 = Conv2d(FEATURES_2, FEATURES_3, (3, 1), 2, (1, 0)) # 16\n",
    "        self.c5 = Conv2d(FEATURES_3, FEATURES_4, (3, 1), 2, (1, 0)) # 8\n",
    "        self.c6 = Conv2d(FEATURES_4, FEATURES_5, (3, 1), 2, (1, 0)) # 2\n",
    "        self.bn = BatchNorm2d(FEATURES_1)\n",
    "        self.bn3 = BatchNorm2d(FEATURES_2)\n",
    "        self.bn4 = BatchNorm2d(FEATURES_3)\n",
    "        self.bn5 = BatchNorm2d(FEATURES_4)\n",
    "        self.bn6 = BatchNorm2d(FEATURES_5)\n",
    "        self.fc1 = Linear(32 * FEATURES_5, 256)\n",
    "        self.fc2 = Linear(256, 64)\n",
    "        self.fc3 = Linear(64, 1)\n",
    "\n",
    "    def _forward_features(self, x):\n",
    "        x = self.bn(F.relu(self.c1(x)))\n",
    "        # x = self.bn(F.relu(self.c2(x) + x))\n",
    "        # x = self.bn(F.relu(self.c2(x) + x))\n",
    "        # x = self.bn(F.relu(self.c2(x) + x))\n",
    "        x = self.bn(F.relu(self.c2(x)))\n",
    "        x = self.bn3(F.relu(self.c3(x)))\n",
    "        x = self.bn4(F.relu(self.c4(x)))\n",
    "        x = self.bn5(F.relu(self.c5(x)))\n",
    "        # x = self.bn6(F.relu(self.c6(x)))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        # print(x.shape)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.mse_loss(logits, y)\n",
    "        mse = mean_squared_error(logits, y)\n",
    "        mae = mean_absolute_error(logits, y)\n",
    "        k = t_kendalltau(logits, y)\n",
    "        p = t_pearson(logits, y)\n",
    "        s = t_spearman(logits, y)\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log(\"train_mse\", mse, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log(\"train_mae\", mae, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log(\"train_kendalltau\", k, on_step=False, on_epoch=True, logger=True)\n",
    "        self.log(\"train_pearson\", p, on_step=False, on_epoch=True, logger=True)\n",
    "        self.log(\"train_spearman\", s, on_step=False, on_epoch=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.mse_loss(logits, y)\n",
    "        mse = mean_squared_error(logits, y)\n",
    "        mae = mean_absolute_error(logits, y)\n",
    "        k = t_kendalltau(logits, y)\n",
    "        p = t_pearson(logits, y)\n",
    "        s = t_spearman(logits, y)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_mse\", mse, prog_bar=True)\n",
    "        self.log(\"val_mae\", mae, prog_bar=True)\n",
    "        self.log(\"val_kendalltau\", k, on_step=False, prog_bar=True)\n",
    "        self.log(\"val_pearson\", p, on_step=False, prog_bar=True)\n",
    "        self.log(\"val_spearman\", s, on_step=False, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.mse_loss(logits, y)\n",
    "        mse = mean_squared_error(logits, y)\n",
    "        mae = mean_absolute_error(logits, y)\n",
    "        k = t_kendalltau(logits, y)\n",
    "        p = t_pearson(logits, y)\n",
    "        s = t_spearman(logits, y)\n",
    "        self.log(\"test_loss\", loss, on_step=True, prog_bar=True)\n",
    "        self.log(\"test_mse\", mse, on_step=True, prog_bar=True)\n",
    "        self.log(\"test_mae\", mae, on_step=True, prog_bar=True)\n",
    "        self.log(\"test_kendalltau\", k, prog_bar=True)\n",
    "        self.log(\"test_pearson\", p, prog_bar=True)\n",
    "        self.log(\"test_spearman\", s, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FourierTransformerDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape,\n",
    "        learning_rate=0.001,\n",
    "        num_layers: int = 6,\n",
    "        dropout: float = 0.1,\n",
    "        dim_ff:int = 2048\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.decoder = FNet(num_layers, input_shape, dim_ff, dropout)\n",
    "        self.fc_bloc = Sequential(\n",
    "            Linear(input_shape, input_shape // (div := 2)),  # 1024 > 512\n",
    "            GELU(),\n",
    "            Dropout(dropout),\n",
    "            Linear(input_shape // div, input_shape // (div := div * 4)),  # 512 > 128\n",
    "            GELU(),\n",
    "            Dropout(dropout),\n",
    "            Linear(input_shape // div, 1),  # 128 > 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.decoder(x)\n",
    "        x = self.fc_bloc(x)\n",
    "        x = torch.tanh(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.mse_loss(logits, y)\n",
    "        mse = mean_squared_error(logits, y)\n",
    "        mae = mean_absolute_error(logits, y)\n",
    "        k = t_kendalltau(logits, y)\n",
    "        p = t_pearson(logits, y)\n",
    "        s = t_spearman(logits, y)\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log(\"train_mse\", mse, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log(\"train_mae\", mae, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log(\"train_kendalltau\", k, on_step=False, on_epoch=True, logger=True)\n",
    "        self.log(\"train_pearson\", p, on_step=False, on_epoch=True, logger=True)\n",
    "        self.log(\"train_spearman\", s, on_step=False, on_epoch=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.mse_loss(logits, y)\n",
    "        mse = mean_squared_error(logits, y)\n",
    "        mae = mean_absolute_error(logits, y)\n",
    "        k = t_kendalltau(logits, y)\n",
    "        p = t_pearson(logits, y)\n",
    "        s = t_spearman(logits, y)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_mse\", mse, prog_bar=True)\n",
    "        self.log(\"val_mae\", mae, prog_bar=True)\n",
    "        self.log(\"val_kendalltau\", k, on_step=False, prog_bar=True)\n",
    "        self.log(\"val_pearson\", p, on_step=False, prog_bar=True)\n",
    "        self.log(\"val_spearman\", s, on_step=False, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.mse_loss(logits, y)\n",
    "        mse = mean_squared_error(logits, y)\n",
    "        mae = mean_absolute_error(logits, y)\n",
    "        k = t_kendalltau(logits, y)\n",
    "        p = t_pearson(logits, y)\n",
    "        s = t_spearman(logits, y)\n",
    "        self.log(\"test_loss\", loss, on_step=True, prog_bar=True)\n",
    "        self.log(\"test_mse\", mse, on_step=True, prog_bar=True)\n",
    "        self.log(\"test_mae\", mae, on_step=True, prog_bar=True)\n",
    "        self.log(\"test_kendalltau\", k, prog_bar=True)\n",
    "        self.log(\"test_pearson\", p, prog_bar=True)\n",
    "        self.log(\"test_spearman\", s, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        optimizer = RAdam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training + Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "pair = \"en-zh\"\n",
    "num_layers = 1  # 2 best results\n",
    "dim_ff = 1024  # 256 best results\n",
    "lr = 0.01  # 0.0001 best results\n",
    "bs = 1024 # 16 best results ## 256\n",
    "dm = TextMiningDataModule(bs, pair, 1024 * 3)\n",
    "dm.setup()\n",
    "model = Model(dm.dims, learning_rate=lr, num_layers=num_layers, dim_ff=dim_ff)\n",
    "# wandb_logger = WandbLogger(project=\"wandb-lightning\", job_type=\"train\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_kendalltau\",\n",
    "    filename=f\"{pair}\"+\"_{epoch:02d}_{val_kendalltau:.3f}\",\n",
    "    mode=\"max\",\n",
    "    save_top_k = 1,\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=75,\n",
    "    progress_bar_refresh_rate=1,\n",
    "    gpus=1,\n",
    "    logger=False,\n",
    "    auto_lr_find=True,\n",
    "    # checkpoint_callback=False\n",
    "    # logger=wandb_logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    ")\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | decoder | FNet       | 6.3 M \n",
      "1 | fc_bloc | Sequential | 2.5 M \n",
      "---------------------------------------\n",
      "8.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.8 M     Total params\n",
      "35.263    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: 100%|██████████| 10/10 [00:01<00:00,  5.68it/s, loss=0.384, val_loss=0.776, val_mae=0.678, val_kendalltau=0.267, val_pearson=0.382]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{'val_kendalltau': 0.27738261222839355,\n",
      " 'val_loss': 0.7160733342170715,\n",
      " 'val_mae': 0.6557644605636597,\n",
      " 'val_pearson': 0.4065486192703247}\n",
      "--------------------------------------------------------------------------------\n",
      "val_loss 0.716\n",
      "val_mae 0.656\n",
      "val_kendalltau 0.277\n",
      "val_pearson 0.407\n"
     ]
    }
   ],
   "source": [
    "# en-zh\n",
    "model = Model.load_from_checkpoint(\"checkpoints/en-zh_epoch=27_val_kendalltau=0.277.ckpt\")\n",
    "model.eval()\n",
    "val_scores = trainer.validate()\n",
    "\n",
    "for k,v in val_scores[0].items():\n",
    "    print(k, round(v, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validated corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{'val_kendalltau': 0.27426302433013916,\n",
      " 'val_loss': 0.6592675447463989,\n",
      " 'val_mae': 0.6607044339179993,\n",
      " 'val_mse': 0.6592675447463989,\n",
      " 'val_pearson': 0.39609044790267944,\n",
      " 'val_spearman': 0.3779524266719818}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ZH-EN\n",
    "val_scores = trainer.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.code.notebook.stderr": [
       "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
      ]
     },
     "output_type": "unknown"
    },
    {
     "data": {
      "application/vnd.code.notebook.stdout": [
       "--------------------------------------------------------------------------------\n",
       "DATALOADER:0 VALIDATE RESULTS\n",
       "{'val_kendalltau': 0.25537145137786865,\n",
       " 'val_loss': 0.649438738822937,\n",
       " 'val_mae': 0.609234631061554,\n",
       " 'val_pearson': 0.3800727427005768}\n",
       "--------------------------------------------------------------------------------\n",
       "val_loss 0.649\n",
       "val_mae 0.609\n",
       "val_kendalltau 0.255\n",
       "val_pearson 0.38\n"
      ]
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "# DE-EN\n",
    "model = Model.load_from_checkpoint(\"checkpoints/de-en_epoch=41_val_kendalltau=0.255.ckpt\")\n",
    "val_scores = trainer.validate()\n",
    "\n",
    "for k,v in val_scores[0].items():\n",
    "    print(k, round(v, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.code.notebook.stderr": [
       "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
      ]
     },
     "output_type": "unknown"
    },
    {
     "data": {
      "application/vnd.code.notebook.stdout": [
       "--------------------------------------------------------------------------------\n",
       "DATALOADER:0 VALIDATE RESULTS\n",
       "{'val_kendalltau': 0.36348140239715576,\n",
       " 'val_loss': 0.5783763527870178,\n",
       " 'val_mae': 0.5771598815917969,\n",
       " 'val_pearson': 0.5237804651260376}\n",
       "--------------------------------------------------------------------------------\n",
       "val_loss 0.578\n",
       "val_mae 0.577\n",
       "val_kendalltau 0.363\n",
       "val_pearson 0.524\n"
      ]
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "# cs-en\n",
    "model = Model.load_from_checkpoint(\"checkpoints/cs-en_epoch=38_val_kendalltau=0.363.ckpt\")\n",
    "val_scores = trainer.validate()\n",
    "\n",
    "for k,v in val_scores[0].items():\n",
    "    print(k, round(v, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.code.notebook.stderr": [
       "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
      ]
     },
     "output_type": "unknown"
    },
    {
     "data": {
      "application/vnd.code.notebook.stdout": [
       "--------------------------------------------------------------------------------\n",
       "DATALOADER:0 VALIDATE RESULTS\n",
       "{'val_kendalltau': 0.3332441747188568,\n",
       " 'val_loss': 0.64165198802948,\n",
       " 'val_mae': 0.6595911979675293,\n",
       " 'val_pearson': 0.48797911405563354}\n",
       "--------------------------------------------------------------------------------\n",
       "val_loss 0.642\n",
       "val_mae 0.66\n",
       "val_kendalltau 0.333\n",
       "val_pearson 0.488\n"
      ]
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "# en-fi\n",
    "model = Model.load_from_checkpoint(\"checkpoints/en-fi_epoch=22_val_kendalltau=0.333.ckpt\")\n",
    "model.eval()\n",
    "val_scores = trainer.validate()\n",
    "\n",
    "for k,v in val_scores[0].items():\n",
    "    print(k, round(v, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.code.notebook.stderr": [
       "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
      ]
     },
     "output_type": "unknown"
    },
    {
     "data": {
      "application/vnd.code.notebook.stdout": [
       "--------------------------------------------------------------------------------\n",
       "DATALOADER:0 VALIDATE RESULTS\n",
       "{'val_kendalltau': 0.2311522662639618,\n",
       " 'val_loss': 0.7340682148933411,\n",
       " 'val_mae': 0.6475061774253845,\n",
       " 'val_pearson': 0.32311367988586426}\n",
       "--------------------------------------------------------------------------------\n",
       "val_loss 0.734\n",
       "val_mae 0.648\n",
       "val_kendalltau 0.231\n",
       "val_pearson 0.323\n"
      ]
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "# ru-en\n",
    "model = Model.load_from_checkpoint(\"checkpoints/ru-en_epoch=15_val_kendalltau=0.231.ckpt\")\n",
    "model.eval()\n",
    "val_scores = trainer.validate()\n",
    "\n",
    "for k,v in val_scores[0].items():\n",
    "    print(k, round(v, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill Test Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28404,)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"de-en\"\n",
    "scored = pd.read_csv(\"scores_de-en_0.255.csv\")[\"metric\"]\n",
    "scored.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28404, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Das Publikum ist fast gleichmäßig zwischen Sch...</td>\n",
       "      <td>The audience is almost evenly split between bl...</td>\n",
       "      <td>The audience is almost evenly split between bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Du kannst ihre Energie durch den Bildschirm sp...</td>\n",
       "      <td>You can feel their energy through the screen. \"\"</td>\n",
       "      <td>You can feel her energy through the screen.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Da die Adresse unbekannt ist, wird die Mithilf...</td>\n",
       "      <td>As the address is unknown, the help of the pop...</td>\n",
       "      <td>As the address is unknown, the assistance of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arsenal-Manager Arsene Wenger, dessen Verein i...</td>\n",
       "      <td>Arsenal manager Arsene Wenger, whose club is o...</td>\n",
       "      <td>Arsenal manager Arsene Wenger, whose club is o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Landwirtschaftsminister im Interview - Wie sch...</td>\n",
       "      <td>Agriculture Minister in the interview - How do...</td>\n",
       "      <td>Minister of Agriculture in interview – How do ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Das Publikum ist fast gleichmäßig zwischen Sch...   \n",
       "1  Du kannst ihre Energie durch den Bildschirm sp...   \n",
       "2  Da die Adresse unbekannt ist, wird die Mithilf...   \n",
       "3  Arsenal-Manager Arsene Wenger, dessen Verein i...   \n",
       "4  Landwirtschaftsminister im Interview - Wie sch...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  The audience is almost evenly split between bl...   \n",
       "1   You can feel their energy through the screen. \"\"   \n",
       "2  As the address is unknown, the help of the pop...   \n",
       "3  Arsenal manager Arsene Wenger, whose club is o...   \n",
       "4  Agriculture Minister in the interview - How do...   \n",
       "\n",
       "                                         translation  \n",
       "0  The audience is almost evenly split between bl...  \n",
       "1       You can feel her energy through the screen.\"  \n",
       "2  As the address is unknown, the assistance of t...  \n",
       "3  Arsenal manager Arsene Wenger, whose club is o...  \n",
       "4  Minister of Agriculture in interview – How do ...  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_fill = pd.read_csv(f\"testset/{path}/scores.csv\").drop(columns=[\"metric\"])\n",
    "print(to_fill.shape)\n",
    "to_fill.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_fill.join(scored).to_csv(f\"filled_scores_{path}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f8b00cba333cbc52f2b9024e2fd0f03f267bd4c88e752638d58a81ffee90e795"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('pl': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}